{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "fluid-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "import copy\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "comprehensive-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "POI_TAG = 0\n",
    "STREET_TAG = 1\n",
    "OTHER_TAG = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "agreed-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./scl-2021-ds/parsed_train.csv\")\n",
    "df = df.dropna()\n",
    "df['parsed'] = df['parsed'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-offset",
   "metadata": {},
   "source": [
    "## Creating Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "complex-daily",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35687256c897431193216a0fc7287d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poi_dict = dict()  # e.g. {neg : {negeri : 10, negara : 1}}\n",
    "street_dict = dict()\n",
    "for i, curr_parsed in tqdm(enumerate(df['parsed'])):\n",
    "    for (token, tag, corrected_token) in curr_parsed:\n",
    "        if tag == POI_TAG:\n",
    "            if token in poi_dict:\n",
    "                if corrected_token not in poi_dict[token]:\n",
    "                    (poi_dict[token])[corrected_token] = 1\n",
    "                (poi_dict[token])[corrected_token] += 1\n",
    "            else:\n",
    "                poi_dict[token] = {corrected_token: 1}\n",
    "        elif tag == STREET_TAG:\n",
    "            if token in street_dict:\n",
    "                if corrected_token not in street_dict[token]:\n",
    "                    (street_dict[token])[corrected_token] = 1\n",
    "                (street_dict[token])[corrected_token] += 1\n",
    "            else:\n",
    "                street_dict[token] = {corrected_token: 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-missile",
   "metadata": {},
   "source": [
    "## Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "latter-execution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change values into % of occurrence\n",
    "for token in poi_dict:\n",
    "    total_count = 0\n",
    "    for correct_token in poi_dict[token]:\n",
    "        total_count += (poi_dict[token])[correct_token]\n",
    "    for correct_token in poi_dict[token]:\n",
    "        (poi_dict[token])[correct_token] *= (100/total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "tired-christianity",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in street_dict:\n",
    "    total_count = 0\n",
    "    for correct_token in street_dict[token]:\n",
    "        total_count += (street_dict[token])[correct_token]\n",
    "    for correct_token in street_dict[token]:\n",
    "        (street_dict[token])[correct_token] *= (100/total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-petersburg",
   "metadata": {},
   "source": [
    "## Saving Dict to Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "selected-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving dict as json file\n",
    "with open(\"postmodel_poi_correction_dict.json\", \"w\") as poi_dict_file:\n",
    "    json.dump(poi_dict, poi_dict_file, indent = 4)\n",
    "poi_dict_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "happy-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"postmodel_street_correction_dict.json\", \"w\") as street_dict_file:\n",
    "    json.dump(street_dict, street_dict_file, indent = 4)\n",
    "street_dict_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-authorization",
   "metadata": {},
   "source": [
    "## Replacing Words in Prediction File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "stunning-bulgarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = pd.read_csv(\"output_bilstm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "southwest-documentary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>POI/street</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>/s. par</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>/angg per</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>asma laun/mand imog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ud agung rej/raya nga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>/cut mutia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>49995</td>\n",
       "      <td>toko mbak farid/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>49996</td>\n",
       "      <td>vie - tk. ridho kids/vete 3 cari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>49997</td>\n",
       "      <td>mart dan roti bakar malabar/nasio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>49998</td>\n",
       "      <td>graha indah/jl. mujair raya bambu apus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>49999</td>\n",
       "      <td>adi/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                              POI/street\n",
       "0          0                                 /s. par\n",
       "1          1                               /angg per\n",
       "2          2                     asma laun/mand imog\n",
       "3          3                   ud agung rej/raya nga\n",
       "4          4                              /cut mutia\n",
       "...      ...                                     ...\n",
       "49995  49995                        toko mbak farid/\n",
       "49996  49996        vie - tk. ridho kids/vete 3 cari\n",
       "49997  49997       mart dan roti bakar malabar/nasio\n",
       "49998  49998  graha indah/jl. mujair raya bambu apus\n",
       "49999  49999                                    adi/\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "accredited-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new dicts mapping k => correct_token with maximum occurrence %\n",
    "poi_dict_max = copy.deepcopy(poi_dict)\n",
    "street_dict_max = copy.deepcopy(street_dict)\n",
    "\n",
    "for k in poi_dict_max:\n",
    "    poi_dict_max[k] = max(poi_dict_max[k], key=lambda key: (poi_dict_max[k])[key])\n",
    "for k in street_dict_max:\n",
    "    street_dict_max[k] = max(street_dict_max[k], key=lambda key: (street_dict_max[k])[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "fluid-mexico",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in output_df.iterrows():\n",
    "    poi_street = row[\"POI/street\"].split('/')\n",
    "    poi = poi_street[0]\n",
    "    street = poi_street[1]\n",
    "    old_poi_street = poi + \"/\" + street\n",
    "    if poi in poi_dict_max:\n",
    "        poi = poi_dict_max[poi]\n",
    "    if street in street_dict_max:\n",
    "        street = street_dict_max[street]\n",
    "    new_poi_street = poi + \"/\" + street\n",
    "    if old_poi_street != new_poi_street:\n",
    "        output_df.loc[i, \"POI/street\"] = new_poi_street"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "concrete-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.to_csv(\"post_output_bilstm_correction.csv\", index=False, index_label=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
