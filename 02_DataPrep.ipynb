{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "indoor-surveillance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T04:11:17.762917Z",
     "start_time": "2021-03-15T04:11:17.760743Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "paperback-piece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T04:05:28.132861Z",
     "start_time": "2021-03-15T04:05:28.131131Z"
    }
   },
   "outputs": [],
   "source": [
    "POI_TAG = 0\n",
    "STREET_TAG = 1\n",
    "OTHER_TAG = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "interstate-funeral",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T04:20:31.279997Z",
     "start_time": "2021-03-15T04:20:30.996143Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./scl-2021-ds/train.csv\")\n",
    "train_df = train_df.astype(object)\n",
    "train_df['parsed'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "short-savage",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T04:20:32.345442Z",
     "start_time": "2021-03-15T04:20:32.343151Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_tokens(string):\n",
    "    string = string.replace(\",\", \" , \")\n",
    "    tokens = string.split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "rough-mining",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T04:40:49.395569Z",
     "start_time": "2021-03-15T04:40:49.388693Z"
    }
   },
   "outputs": [],
   "source": [
    "def EditDistDP(str1, str2):\n",
    "    \"\"\"\n",
    "    From https://www.geeksforgeeks.org/edit-distance-dp-5/\n",
    "    \"\"\"\n",
    "    len1 = len(str1)\n",
    "    len2 = len(str2)\n",
    " \n",
    "    # Create a DP array to memoize result\n",
    "    # of previous computations\n",
    "    DP = [[0 for i in range(len1 + 1)] \n",
    "             for j in range(2)];\n",
    " \n",
    "    # Base condition when second String\n",
    "    # is empty then we remove all characters\n",
    "    for i in range(0, len1 + 1):\n",
    "        DP[0][i] = i\n",
    " \n",
    "    # Start filling the DP\n",
    "    # This loop run for every\n",
    "    # character in second String\n",
    "    for i in range(1, len2 + 1):\n",
    "         \n",
    "        # This loop compares the char from\n",
    "        # second String with first String\n",
    "        # characters\n",
    "        for j in range(0, len1 + 1):\n",
    " \n",
    "            # If first String is empty then\n",
    "            # we have to perform add character\n",
    "            # operation to get second String\n",
    "            if (j == 0):\n",
    "                DP[i % 2][j] = i\n",
    " \n",
    "            # If character from both String\n",
    "            # is same then we do not perform any\n",
    "            # operation . here i % 2 is for bound\n",
    "            # the row number.\n",
    "            elif(str1[j - 1] == str2[i-1]):\n",
    "                DP[i % 2][j] = DP[(i - 1) % 2][j - 1]\n",
    "             \n",
    "            # If character from both String is\n",
    "            # not same then we take the minimum\n",
    "            # from three specified operation\n",
    "            else:\n",
    "                DP[i%2][j] = min(\n",
    "                    1 + DP[(i-1)%2][j], # insertion cost = 1\n",
    "                    100 + DP[i%2][j-1], # deletion cost = 100\n",
    "                    100 + DP[(i-1)%2][j-1], # substitution cost = 100\n",
    "                )\n",
    "             \n",
    "    # After complete fill the DP array\n",
    "    # if the len2 is even then we end\n",
    "    # up in the 0th row else we end up\n",
    "    # in the 1th row so we take len2 % 2\n",
    "    # to get row\n",
    "    return DP[len2 % 2][len1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "macro-flooring",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T04:44:59.141848Z",
     "start_time": "2021-03-15T04:44:59.138852Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_exact(base_tokens, pattern_tokens):\n",
    "    for start in range(len(base_tokens)):\n",
    "        end = start + tokens_length\n",
    "        if end > len(pattern_tokens):\n",
    "            return -1\n",
    "        if base_tokens[start:end] == pattern_tokens:\n",
    "            return start\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "possible-electric",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T04:58:08.977669Z",
     "start_time": "2021-03-15T04:58:08.973854Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_almost_exact(base_tokens, pattern_tokens):\n",
    "    # Almost match\n",
    "    best_dist = 1e9\n",
    "    best_start = -1\n",
    "    for start in range(len(base_tokens)):\n",
    "        end = start + len(pattern_tokens)\n",
    "        if end > len(base_tokens):\n",
    "            break\n",
    "\n",
    "        dist = EditDistDP(' '.join(base_tokens[start:end]), ' '.join(pattern_tokens))\n",
    "        if dist < best_dist:\n",
    "            best_dist = dist\n",
    "            best_start = start\n",
    "    return best_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "compact-harassment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T05:06:58.704023Z",
     "start_time": "2021-03-15T05:03:47.727305Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd34f896c6846f790c1e94dd508372f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for idx, row in tqdm(train_df.iterrows(), total=train_df.shape[0]):\n",
    "    raw_address = row['raw_address']\n",
    "    POI, street = row['POI/street'].split('/')\n",
    "    \n",
    "    raw_tokens = to_tokens(raw_address)\n",
    "    POI_tokens = to_tokens(POI)\n",
    "    street_tokens = to_tokens(street)\n",
    "    \n",
    "    outputs = np.array([(x, OTHER_TAG, x) for x in raw_tokens])\n",
    "\n",
    "    if len(POI_tokens) == 0 and len(street_tokens) == 0:\n",
    "        train_df.at[idx, 'parsed'] = outputs\n",
    "    elif len(POI_tokens) == 0:\n",
    "        exact_loc = find_exact(raw_tokens, street_tokens)\n",
    "        if exact_loc != -1:\n",
    "            start, end = exact_loc, exact_loc + len(street_tokens)\n",
    "            for x in range(start, end):\n",
    "                outputs[x] = (outputs[x][0], STREET_TAG, street_tokens[x-start])\n",
    "        else:\n",
    "            almost_exact_loc = find_almost_exact(raw_tokens, street_tokens)\n",
    "            if almost_exact_loc != -1:\n",
    "                start, end = almost_exact_loc, almost_exact_loc + len(street_tokens)\n",
    "                for x in range(start, end):\n",
    "                    outputs[x] = (outputs[x][0], STREET_TAG, street_tokens[x-start])\n",
    "            else:\n",
    "                outputs = None\n",
    "            \n",
    "        train_df.at[idx, 'parsed'] = outputs\n",
    "    elif len(street_tokens) == 0:\n",
    "        exact_loc = find_exact(raw_tokens, POI_tokens)\n",
    "        if exact_loc != -1:\n",
    "            start, end = exact_loc, exact_loc + len(POI_tokens)\n",
    "            for x in range(start, end):\n",
    "                outputs[x] = (outputs[x][0], POI_TAG, POI_tokens[x-start])\n",
    "        else:\n",
    "            almost_exact_loc = find_almost_exact(raw_tokens, POI_tokens)\n",
    "            if almost_exact_loc != -1:\n",
    "                start, end = almost_exact_loc, almost_exact_loc + len(POI_tokens)\n",
    "                for x in range(start, end):\n",
    "                    outputs[x] = (outputs[x][0], POI_TAG, POI_tokens[x-start])   \n",
    "            else:\n",
    "                outputs = None\n",
    "                \n",
    "        train_df.at[idx, 'parsed'] = outputs\n",
    "    else:\n",
    "        # Do Street first\n",
    "        exact_loc = find_exact(raw_tokens, street_tokens)\n",
    "        if exact_loc != -1:\n",
    "            start, end = exact_loc, exact_loc + len(street_tokens)\n",
    "            for x in range(start, end):\n",
    "                outputs[x] = (outputs[x][0], STREET_TAG, street_tokens[x-start])\n",
    "        else:\n",
    "            almost_exact_loc = find_almost_exact(raw_tokens, street_tokens)\n",
    "            if almost_exact_loc != -1:\n",
    "                start, end = almost_exact_loc, almost_exact_loc + len(street_tokens)\n",
    "                for x in range(start, end):\n",
    "                    outputs[x] = (outputs[x][0], STREET_TAG, street_tokens[x-start])\n",
    "            else:\n",
    "                outputs = None\n",
    "        \n",
    "        if outputs is not None:\n",
    "            exact_loc = find_exact(raw_tokens, POI_tokens)\n",
    "            if exact_loc != -1:\n",
    "                start, end = exact_loc, exact_loc + len(POI_tokens)\n",
    "                for x in range(start, end):\n",
    "                    outputs[x] = (outputs[x][0], POI_TAG, POI_tokens[x-start])\n",
    "            else:\n",
    "                almost_exact_loc = find_almost_exact(raw_tokens, POI_tokens)\n",
    "                if almost_exact_loc != -1:\n",
    "                    start, end = almost_exact_loc, almost_exact_loc + len(POI_tokens)\n",
    "                    for x in range(start, end):\n",
    "                        outputs[x] = (outputs[x][0], POI_TAG, POI_tokens[x-start])   \n",
    "                else:\n",
    "                    outputs = None\n",
    "\n",
    "        train_df.at[idx, 'parsed'] = outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "narrative-journalist",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-15T05:09:59.349141Z",
     "start_time": "2021-03-15T05:09:44.502542Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.to_csv(\"./scl-2021-ds/parsed_train.csv\", index=False, index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "representative-boutique",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
