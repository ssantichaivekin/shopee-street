{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "heavy-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "from typing import Dict, Union, Any, List, Tuple\n",
    "import numpy as np\n",
    "from numpy.core.multiarray import ndarray\n",
    "from bpemb import BPEmb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "fundamental-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {\n",
    "    \"POI\": 0,\n",
    "    \"StreetName\": 1,\n",
    "    \"Others\": 2,\n",
    "    \"EOS\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-cooperative",
   "metadata": {},
   "source": [
    "## Tags Coverter\n",
    "\n",
    "`TagsCoverter` is a utility class for converting between tag ID and tag name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "listed-delivery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/GRAAL-Research/deepparse/blob/0951ffa18b0838fbd536d8d607695f1667d9939a/deepparse/converter/target_converter.py\n",
    "\n",
    "class TagsConverter:\n",
    "    \"\"\"\n",
    "    Class to define logic of tag to idx conversion and vice versa.\n",
    "    Args:\n",
    "        tags_to_idx (Dict): A dictionary where the keys are the tags (e.g. StreetNumber) and the values are\n",
    "            the indexes (int) (e.g. 1).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tags_to_idx: Dict) -> None:\n",
    "        self.tags_to_idx = tags_to_idx\n",
    "        self.idx_to_tags = {v: k for k, v in tags_to_idx.items()}\n",
    "\n",
    "    def __call__(self, key: Union[str, int]) -> int:\n",
    "        \"\"\"\n",
    "        If str convert from a tag to idx and if int convert from a idx to a tag using the convert table.\n",
    "        \"\"\"\n",
    "        if isinstance(key, str):\n",
    "            return self.tags_to_idx[key]\n",
    "        return self.idx_to_tags[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "parental-philip",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_ids = TagsConverter(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "otherwise-conjunction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'StreetName')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_ids('POI'), tags_ids(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-preserve",
   "metadata": {},
   "source": [
    "## Token -> Subword Embeddings\n",
    "\n",
    "`BPEmb` is a way to convert between string to subword embeddings. In this model, we have $10^5$ subwords and each subword has an embedding of dimension 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "amino-moldova",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = BPEmb(lang=\"multi\", vs=100000, dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "offensive-notice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁h', 'ello', '▁ave', '▁fast']"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.encode(\"Hello ave fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "complex-juice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35, 3333]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.encode_ids(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "extreme-essay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 300)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.embed(\"hello\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-research",
   "metadata": {},
   "source": [
    "## Vectorizer\n",
    "\n",
    "`BPEmbVectorizer` is a class for converting a list of addresses into nested array subword embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bridal-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/GRAAL-Research/deepparse/blob/0951ffa18b0838fbd536d8d607695f1667d9939a/deepparse/vectorizer/bpemb_vectorizer.py#L9\n",
    "\n",
    "class BPEmbVectorizer:\n",
    "    \"\"\"\n",
    "    BPEmb vectorizer to convert an address into BPEmb embedding where each word is decomposed into subword units that\n",
    "    are in turn embedded as a vector\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embeddings_model: Any) -> None:\n",
    "        self.embeddings_model = embeddings_model\n",
    "        self.padding_value = 0\n",
    "\n",
    "    def __call__(self, addresses: List[str]) -> List[Tuple]:\n",
    "        \"\"\"\n",
    "        Method to vectorizer addresses.\n",
    "        Args:\n",
    "            addresses (list[str]): The addresses to vectorize.\n",
    "        Return:\n",
    "            A tuple of the addresses elements (components) embedding vectosr and the word decomposition lengths.\n",
    "        \"\"\"\n",
    "        self._max_length = 0\n",
    "        batch = [self._vectorize_sequence(address) for address in addresses]\n",
    "        self._decomposed_sequence_padding(batch)\n",
    "        return batch\n",
    "\n",
    "    def _vectorize_sequence(self, address: str) -> Tuple[List, List]:\n",
    "        \"\"\"\n",
    "        Method to vectorize the address.\n",
    "        Args:\n",
    "            address (str): Address to vectorize using BPEmb.\n",
    "        Return:\n",
    "            A tuple of list of word vector and the word decomposition lengths.\n",
    "        \"\"\"\n",
    "        input_sequence = []\n",
    "        word_decomposition_lengths = []\n",
    "        address = address.replace(\",\", \"\")  # see issue 56 https://github.com/GRAAL-Research/deepparse/issues/56\n",
    "        for word in address.split():\n",
    "            bpe_decomposition = self.embeddings_model.embed(word)\n",
    "            word_decomposition_lengths.append(len(bpe_decomposition))\n",
    "            input_sequence.append(list(bpe_decomposition))\n",
    "\n",
    "        self._max_length = max(self._max_length, max(word_decomposition_lengths))\n",
    "\n",
    "        return input_sequence, word_decomposition_lengths\n",
    "\n",
    "    def _decomposed_sequence_padding(self, batch: List[Tuple]) -> None:\n",
    "        \"\"\"\n",
    "        Method to add padding to the decomposed sequence.\n",
    "        \"\"\"\n",
    "        for decomposed_sequence, _ in batch:\n",
    "            for decomposition in decomposed_sequence:\n",
    "                if len(decomposition) != self._max_length:\n",
    "                    decomposition.extend([np.ones(self.embeddings_model.dim) * [self.padding_value]] *\n",
    "                                         (self._max_length - len(decomposition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bibliographic-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = BPEmbVectorizer(embeddings_model=emb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "revolutionary-myanmar",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = vectorizer([\"Hello ave fast\"])\n",
    "# output[0] => \"Hello ave\"\n",
    "# output[0][0] => embeddings\n",
    "#     output[0][0][0] => Hello\n",
    "#     output[0][0][1] => Ave\n",
    "# output[0][1] => length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "secure-ethnic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "cooperative-incident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 1]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-classic",
   "metadata": {},
   "source": [
    "## Padding to torch Tensor\n",
    "\n",
    "Note that different addresses may have different number of subwords. To handle this, we pad the tensor with zeros. `bpemb_data_padding` handles the padding and converts the nested array of subwords to `torch.Tensor` of padded subword embedding and its length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "united-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/GRAAL-Research/deepparse/blob/0951ffa18b0838fbd536d8d607695f1667d9939a/deepparse/converter/data_padding.py#L36\n",
    "\n",
    "def bpemb_data_padding(batch: List[Tuple], padding_value=-100) -> Tuple:\n",
    "    \"\"\"\n",
    "    Function that add padding to the sequences and to the decomposition lengths so all can have the same length as\n",
    "    the longest one.\n",
    "    Args:\n",
    "        batch (list[tuple]): The list of vectorize tupled batch data where the first element is the address embeddings\n",
    "            and the second is the word decomposition lengths.\n",
    "    Returns:\n",
    "        A tuple (``x``, ``y``, ``z``). The element ``x`` is a tensor of padded word vectors, ``y`` is the padded\n",
    "        decomposition lengths, and ``z`` is the original lengths of the sequences before padding.\n",
    "    \"\"\"\n",
    "\n",
    "    sequences_vectors, decomp_len, lengths = zip(\n",
    "        *[(torch.tensor(vectors), word_decomposition_len, len(vectors))\n",
    "          for vectors, word_decomposition_len in sorted(batch, key=lambda x: len(x[0]), reverse=True)])\n",
    "\n",
    "    lengths = torch.tensor(lengths)\n",
    "\n",
    "    padded_sequences_vectors = pad_sequence(sequences_vectors, batch_first=True, padding_value=padding_value)\n",
    "\n",
    "    # pad decomposition length\n",
    "    max_sequence_length = lengths.max().item()\n",
    "    for decomposition_length in decomp_len:\n",
    "        if len(decomposition_length) < max_sequence_length:\n",
    "            decomposition_length.extend([1] * (max_sequence_length - len(decomposition_length)))\n",
    "\n",
    "    return padded_sequences_vectors, list(decomp_len), lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "consistent-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_output = bpemb_data_padding(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "offensive-allah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.1198, -0.0876, -0.3663,  ..., -0.1264,  0.0360,  0.3640],\n",
       "           [ 0.3029, -0.0928, -0.3175,  ...,  0.5222, -0.1151,  0.2372]],\n",
       " \n",
       "          [[ 0.2716, -0.3184,  0.4688,  ...,  0.5481,  0.2733, -0.5135],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "          [[-0.0346, -0.1021, -0.7138,  ..., -0.5223, -0.0465, -0.0476],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "        dtype=torch.float64),\n",
       " [[2, 1, 1]],\n",
       " tensor([3]))"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-airfare",
   "metadata": {},
   "source": [
    "## Seq2Seq Model\n",
    "\n",
    "Here is a simple model modified from deepparse. It takes a sequence of subword embeddings and outputs tagging probability for each subword.\n",
    "\n",
    "For example, the string `\"Hello ave fast\"` has 4 subwords `['▁h', 'ello', '▁ave', '▁fast']`. The model outputs a tensor of shape `(n_subwords, 4)` indicating the logits of the particular subword having certain tag. Currently, we have 4 tags, as follows: POI, Street Name, Others, End-of-String.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "defensive-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://github.com/GRAAL-Research/deepparse/blob/0951ffa18b0838fbd536d8d607695f1667d9939a/deepparse/network/bpemb_seq2seq.py#L9\n",
    "\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding network\n",
    "        self.embedding_input_size = 300\n",
    "        self.embedding_hidden_size = 300\n",
    "        self.embedding_num_layers = 1\n",
    "        self.embedding = nn.LSTM(self.embedding_input_size, \n",
    "                                 self.embedding_hidden_size, \n",
    "                                 num_layers=self.embedding_num_layers,\n",
    "                                 batch_first=True,\n",
    "                                 bidirectional=True)\n",
    "\n",
    "        self.embedding_projection_size = 300\n",
    "        self.embdding_projection = nn.Linear(2 * self.embedding_hidden_size, self.embedding_projection_size)\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder_input_size = 300\n",
    "        self.encoder_hidden_size = 1024\n",
    "        self.encoder_num_layers = 1\n",
    "        self.encoder = nn.LSTM(self.encoder_input_size, \n",
    "                               self.encoder_hidden_size,\n",
    "                               num_layers=self.encoder_num_layers, \n",
    "                               batch_first=True)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_input_size = 1\n",
    "        self.decoder_hidden_size = 1024\n",
    "        self.decoder_num_layers = 1\n",
    "        self.decoder = nn.LSTM(self.decoder_input_size, \n",
    "                               self.decoder_hidden_size,\n",
    "                               num_layers=self.decoder_num_layers, \n",
    "                               batch_first=True)\n",
    "        \n",
    "        self.decoder_projection_output_size = 4\n",
    "        self.decoder_projection = []\n",
    "        self.decoder_projection.append(nn.Linear(self.decoder_hidden_size, self.decoder_projection_output_size))\n",
    "        self.decoder_projection.append(nn.LogSoftmax(dim=1))\n",
    "        self.decoder_projection = nn.Sequential(*self.decoder_projection)\n",
    "        \n",
    "    def forward(self, \n",
    "                to_predict: torch.Tensor, \n",
    "                decomposition_lengths: List, \n",
    "                lengths_tensor: torch.Tensor,\n",
    "                target: Union[torch.Tensor, None] = None) -> torch.Tensor:\n",
    "        device = to_predict.device\n",
    "        batch_size = to_predict.size(0)\n",
    "        \n",
    "        #### Get embedded output\n",
    "        embeddings = torch.zeros(to_predict.size(1), to_predict.size(0), to_predict.size(3)).to(device)\n",
    "        to_predict = to_predict.transpose(0, 1).float()\n",
    "        \n",
    "        for i in range(to_predict.size(0)):\n",
    "            lengths = []\n",
    "            \n",
    "            for decomposition_length in decomposition_lengths:\n",
    "                lengths.append(decomposition_length[i])\n",
    "            \n",
    "            packed_sequence = pack_padded_sequence(to_predict[i], torch.tensor(lengths).cpu(), batch_first=True, enforce_sorted=False)\n",
    "            packed_output, _ = self.embedding(packed_sequence)\n",
    "            padded_output, padded_output_lengths = pad_packed_sequence(packed_output, batch_first=True)\n",
    "            \n",
    "            word_context = torch.zeros(padded_output.size(0), padded_output.size(2)).to(device)\n",
    "            for j in range(batch_size):\n",
    "                word_context[j] = padded_output[j, padded_output_lengths[j] - 1, :]\n",
    "            \n",
    "            projection_output = self.embdding_projection(word_context)\n",
    "            \n",
    "            embeddings[i] = projection_output\n",
    "        \n",
    "        embeddings = embeddings.transpose(0, 1)\n",
    "                \n",
    "        #### Encoder\n",
    "        packed_sequence = pack_padded_sequence(embeddings, lengths_tensor.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, decoder_hidden = self.encoder(packed_sequence)\n",
    "        decoder_input = torch.zeros(1, batch_size, 1).to(device).new_full((1, batch_size, 1), -1)\n",
    "        \n",
    "        #### Decoder\n",
    "        max_length = lengths_tensor[0].item()\n",
    "        prediction_sequence = torch.zeros(max_length + 1, batch_size, 4).to(device)\n",
    "        decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "        decoder_output = self.decoder_projection(decoder_output[0])\n",
    "        \n",
    "        prediction_sequence[0] = decoder_output\n",
    "        _, decoder_input = decoder_output.topk(1)\n",
    "        \n",
    "        if target is not None and random.random() < 0.5:\n",
    "            target = target.transpose(0, 1)\n",
    "            for idx in range(max_length):\n",
    "                decoder_input = target[idx].view(1, batch_size, 1)\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "                decoder_output = self.decoder_projection(decoder_output[0])\n",
    "                prediction_sequence[idx + 1] = decoder_output\n",
    "        else:\n",
    "            for idx in range(max_length):\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input.view(1, batch_size, 1).float(), decoder_hidden)\n",
    "                decoder_output = self.decoder_projection(decoder_output[0])\n",
    "                prediction_sequence[idx + 1] = decoder_output\n",
    "                _, decoder_input = decoder_output.topk(1)\n",
    "                \n",
    "        return prediction_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "defensive-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = BPEmb(lang=\"multi\", vs=100000, dim=300)\n",
    "vectorizer = BPEmbVectorizer(embeddings_model=emb_model)\n",
    "model = Seq2SeqModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "decent-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = vectorizer([\"Hello ave fast\"])\n",
    "padded_output = bpemb_data_padding(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "tested-screw",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(*padded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "critical-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_predictions = predictions.max(2)[1].transpose(0, 1).cpu().numpy()\n",
    "tags_predictions_prob = torch.exp(predictions.max(2)[0]).transpose(0, 1).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "protected-workplace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2530992 , 0.2529205 , 0.25370014, 0.25450543]], dtype=float32)"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_predictions_prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
