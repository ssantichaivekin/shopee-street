{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "norwegian-housing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:30.231374Z",
     "start_time": "2021-03-14T13:43:29.768836Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "from ast import literal_eval\n",
    "from typing import Dict, Union, Any, List, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.core.multiarray import ndarray\n",
    "from tqdm.notebook import tqdm\n",
    "from bpemb import BPEmb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metropolitan-penny",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:30.769183Z",
     "start_time": "2021-03-14T13:43:30.767293Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_CSV_PATH = './santi/deepparse_clean_only_train_split.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "informative-european",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:31.127952Z",
     "start_time": "2021-03-14T13:43:31.125718Z"
    }
   },
   "outputs": [],
   "source": [
    "tags = {\n",
    "    \"PointOfInterest\": 0,\n",
    "    \"Street\": 1,\n",
    "    \"Other\": 2,\n",
    "    \"EOS\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-denver",
   "metadata": {},
   "source": [
    "## Tags Coverter\n",
    "\n",
    "`TagsCoverter` is a utility class for converting between tag ID and tag name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worldwide-species",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:31.566528Z",
     "start_time": "2021-03-14T13:43:31.561634Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/GRAAL-Research/deepparse/blob/0951ffa18b0838fbd536d8d607695f1667d9939a/deepparse/converter/target_converter.py\n",
    "\n",
    "class TagsConverter:\n",
    "    \"\"\"\n",
    "    Class to define logic of tag to idx conversion and vice versa.\n",
    "    Args:\n",
    "        tags_to_idx (Dict): A dictionary where the keys are the tags (e.g. StreetNumber) and the values are\n",
    "            the indexes (int) (e.g. 1).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tags_to_idx: Dict) -> None:\n",
    "        self.tags_to_idx = tags_to_idx\n",
    "        self.idx_to_tags = {v: k for k, v in tags_to_idx.items()}\n",
    "\n",
    "    def __call__(self, key: Union[str, int]) -> int:\n",
    "        \"\"\"\n",
    "        If str convert from a tag to idx and if int convert from a idx to a tag using the convert table.\n",
    "        \"\"\"\n",
    "        if isinstance(key, str):\n",
    "            return self.tags_to_idx[key]\n",
    "        return self.idx_to_tags[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "supreme-burden",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:31.797013Z",
     "start_time": "2021-03-14T13:43:31.794998Z"
    }
   },
   "outputs": [],
   "source": [
    "tags_converter = TagsConverter(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "incomplete-sculpture",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:32.034350Z",
     "start_time": "2021-03-14T13:43:32.025668Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'PointOfInterest')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_converter('PointOfInterest'), tags_converter(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-mozambique",
   "metadata": {},
   "source": [
    "## Token -> Subword Embeddings\n",
    "\n",
    "`BPEmb` is a way to convert between string to subword embeddings. In this model, we have $10^5$ subwords and each subword has an embedding of dimension 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "social-agency",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:33.305764Z",
     "start_time": "2021-03-14T13:43:32.497852Z"
    }
   },
   "outputs": [],
   "source": [
    "emb_model = BPEmb(lang=\"multi\", vs=100000, dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "coupled-appeal",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:33.309532Z",
     "start_time": "2021-03-14T13:43:33.306865Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁h', 'ello', '▁ave', '▁fast']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.encode(\"Hello ave fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "specific-rescue",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:33.317457Z",
     "start_time": "2021-03-14T13:43:33.310546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35, 3333]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.encode_ids(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fleet-cassette",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:33.320832Z",
     "start_time": "2021-03-14T13:43:33.318311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 300)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.embed(\"hello\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-annex",
   "metadata": {},
   "source": [
    "## Vectorizer\n",
    "\n",
    "`BPEmbVectorizer` is a class for converting a list of addresses into nested array subword embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "french-malawi",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:33.583209Z",
     "start_time": "2021-03-14T13:43:33.576727Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/GRAAL-Research/deepparse/blob/0951ffa18b0838fbd536d8d607695f1667d9939a/deepparse/vectorizer/bpemb_vectorizer.py#L9\n",
    "\n",
    "class BPEmbVectorizer:\n",
    "    \"\"\"\n",
    "    BPEmb vectorizer to convert an address into BPEmb embedding where each word is decomposed into subword units that\n",
    "    are in turn embedded as a vector\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embeddings_model: Any) -> None:\n",
    "        self.embeddings_model = embeddings_model\n",
    "        self.padding_value = 0\n",
    "\n",
    "    def __call__(self, addresses: List[str]) -> List[Tuple]:\n",
    "        \"\"\"\n",
    "        Method to vectorizer addresses.\n",
    "        Args:\n",
    "            addresses (list[str]): The addresses to vectorize.\n",
    "        Return:\n",
    "            A tuple of the addresses elements (components) embedding vectosr and the word decomposition lengths.\n",
    "        \"\"\"\n",
    "        self._max_length = 0\n",
    "        batch = [self._vectorize_sequence(address) for address in addresses]\n",
    "        self._decomposed_sequence_padding(batch)\n",
    "        return batch\n",
    "\n",
    "    def _vectorize_sequence(self, address: str) -> Tuple[List, List]:\n",
    "        \"\"\"\n",
    "        Method to vectorize the address.\n",
    "        Args:\n",
    "            address (str): Address to vectorize using BPEmb.\n",
    "        Return:\n",
    "            A tuple of list of word vector and the word decomposition lengths.\n",
    "        \"\"\"\n",
    "        input_sequence = []\n",
    "        word_decomposition_lengths = []\n",
    "#         address = address.replace(\",\", \"\")  # see issue 56 https://github.com/GRAAL-Research/deepparse/issues/56\n",
    "        for word in address.split():\n",
    "            bpe_decomposition = self.embeddings_model.embed(word)\n",
    "            word_decomposition_lengths.append(len(bpe_decomposition))\n",
    "            input_sequence.append(list(bpe_decomposition))\n",
    "\n",
    "        self._max_length = max(self._max_length, max(word_decomposition_lengths))\n",
    "\n",
    "        return input_sequence, word_decomposition_lengths\n",
    "\n",
    "    def _decomposed_sequence_padding(self, batch: List[Tuple]) -> None:\n",
    "        \"\"\"\n",
    "        Method to add padding to the decomposed sequence.\n",
    "        \"\"\"\n",
    "        for decomposed_sequence, _ in batch:\n",
    "            for decomposition in decomposed_sequence:\n",
    "                if len(decomposition) != self._max_length:\n",
    "                    decomposition.extend([np.ones(self.embeddings_model.dim) * [self.padding_value]] *\n",
    "                                         (self._max_length - len(decomposition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "verified-saying",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:33.801284Z",
     "start_time": "2021-03-14T13:43:33.799304Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = BPEmbVectorizer(embeddings_model=emb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "amended-nature",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:33.980843Z",
     "start_time": "2021-03-14T13:43:33.978647Z"
    }
   },
   "outputs": [],
   "source": [
    "output = vectorizer([\"Hello ave fast\"])\n",
    "# output[0] => \"Hello ave\"\n",
    "# output[0][0] => embeddings\n",
    "#     output[0][0][0] => Hello\n",
    "#     output[0][0][1] => Ave\n",
    "# output[0][1] => length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "suspected-semiconductor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:34.181865Z",
     "start_time": "2021-03-14T13:43:34.179166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "worth-savannah",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:34.371016Z",
     "start_time": "2021-03-14T13:43:34.367917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-delicious",
   "metadata": {},
   "source": [
    "## Padding to torch Tensor\n",
    "\n",
    "Note that different addresses may have different number of subwords. To handle this, we pad the tensor with zeros. `bpemb_data_padding` handles the padding and converts the nested array of subwords to `torch.Tensor` of padded subword embedding and its length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "thick-liberty",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:34.789605Z",
     "start_time": "2021-03-14T13:43:34.784873Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/GRAAL-Research/deepparse/blob/0951ffa18b0838fbd536d8d607695f1667d9939a/deepparse/converter/data_padding.py#L36\n",
    "\n",
    "def bpemb_data_padding(batch: List[Tuple], padding_value=-100) -> Tuple:\n",
    "    \"\"\"\n",
    "    Function that add padding to the sequences and to the decomposition lengths so all can have the same length as\n",
    "    the longest one.\n",
    "    Args:\n",
    "        batch (list[tuple]): The list of vectorize tupled batch data where the first element is the address embeddings\n",
    "            and the second is the word decomposition lengths.\n",
    "    Returns:\n",
    "        A tuple (``x``, ``y``, ``z``). The element ``x`` is a tensor of padded word vectors, ``y`` is the padded\n",
    "        decomposition lengths, and ``z`` is the original lengths of the sequences before padding.\n",
    "    \"\"\"\n",
    "\n",
    "    sequences_vectors, decomp_len, lengths = zip(\n",
    "        *[(torch.tensor(vectors), word_decomposition_len, len(vectors))\n",
    "          for vectors, word_decomposition_len in sorted(batch, key=lambda x: len(x[0]), reverse=True)])\n",
    "\n",
    "    lengths = torch.tensor(lengths)\n",
    "\n",
    "    padded_sequences_vectors = pad_sequence(sequences_vectors, batch_first=True, padding_value=padding_value)\n",
    "\n",
    "    # pad decomposition length\n",
    "    max_sequence_length = lengths.max().item()\n",
    "    for decomposition_length in decomp_len:\n",
    "        if len(decomposition_length) < max_sequence_length:\n",
    "            decomposition_length.extend([1] * (max_sequence_length - len(decomposition_length)))\n",
    "\n",
    "    return padded_sequences_vectors, list(decomp_len), lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "compound-snapshot",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:35.000129Z",
     "start_time": "2021-03-14T13:43:34.997260Z"
    }
   },
   "outputs": [],
   "source": [
    "padded_output = bpemb_data_padding(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "phantom-confidentiality",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:35.211065Z",
     "start_time": "2021-03-14T13:43:35.206970Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.1198, -0.0876, -0.3663,  ..., -0.1264,  0.0360,  0.3640],\n",
       "           [ 0.3029, -0.0928, -0.3175,  ...,  0.5222, -0.1151,  0.2372]],\n",
       " \n",
       "          [[ 0.2716, -0.3184,  0.4688,  ...,  0.5481,  0.2733, -0.5135],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "          [[-0.0346, -0.1021, -0.7138,  ..., -0.5223, -0.0465, -0.0476],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "        dtype=torch.float64),\n",
       " [[2, 1, 1]],\n",
       " tensor([3]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-marijuana",
   "metadata": {},
   "source": [
    "## Seq2Seq Model\n",
    "\n",
    "Here is a simple model modified from deepparse. It takes a sequence of subword embeddings and outputs tagging probability for each subword.\n",
    "\n",
    "For example, the string `\"Hello ave fast\"` has 4 subwords `['▁h', 'ello', '▁ave', '▁fast']`. The model outputs a tensor of shape `(n_subwords, 4)` indicating the logits of the particular subword having certain tag. Currently, we have 4 tags, as follows: POI, Street Name, Others, End-of-String.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "danish-trailer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:35.659554Z",
     "start_time": "2021-03-14T13:43:35.642527Z"
    }
   },
   "outputs": [],
   "source": [
    "# adapted from https://github.com/GRAAL-Research/deepparse/blob/0951ffa18b0838fbd536d8d607695f1667d9939a/deepparse/network/bpemb_seq2seq.py#L9\n",
    "\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding network\n",
    "        self.embedding_input_size = 300\n",
    "        self.embedding_hidden_size = 300\n",
    "        self.embedding_num_layers = 1\n",
    "        self.embedding = nn.LSTM(self.embedding_input_size, \n",
    "                                 self.embedding_hidden_size, \n",
    "                                 num_layers=self.embedding_num_layers,\n",
    "                                 batch_first=True,\n",
    "                                 bidirectional=True)\n",
    "\n",
    "        self.embedding_projection_size = 300\n",
    "        self.embdding_projection = nn.Linear(2 * self.embedding_hidden_size, self.embedding_projection_size)\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder_input_size = 300\n",
    "        self.encoder_hidden_size = 1024\n",
    "        self.encoder_num_layers = 1\n",
    "        self.encoder = nn.LSTM(self.encoder_input_size, \n",
    "                               self.encoder_hidden_size,\n",
    "                               num_layers=self.encoder_num_layers, \n",
    "                               batch_first=True)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_input_size = 1\n",
    "        self.decoder_hidden_size = 1024\n",
    "        self.decoder_num_layers = 1\n",
    "        self.decoder = nn.LSTM(self.decoder_input_size, \n",
    "                               self.decoder_hidden_size,\n",
    "                               num_layers=self.decoder_num_layers)\n",
    "        \n",
    "        self.decoder_projection_output_size = 4\n",
    "        self.decoder_projection = []\n",
    "        self.decoder_projection.append(nn.Linear(self.decoder_hidden_size, self.decoder_projection_output_size))\n",
    "        self.decoder_projection.append(nn.LogSoftmax(dim=1))\n",
    "        self.decoder_projection = nn.Sequential(*self.decoder_projection)\n",
    "        \n",
    "    def forward(self, \n",
    "                to_predict: torch.Tensor, \n",
    "                decomposition_lengths: List, \n",
    "                lengths_tensor: torch.Tensor,\n",
    "                target: Union[torch.Tensor, None] = None) -> torch.Tensor:\n",
    "        device = to_predict.device\n",
    "        batch_size = to_predict.size(0)\n",
    "        \n",
    "        #### Get embedded output\n",
    "        embeddings = torch.zeros(to_predict.size(1), to_predict.size(0), to_predict.size(3)).to(device)\n",
    "        to_predict = to_predict.transpose(0, 1).float()\n",
    "        \n",
    "        for i in range(to_predict.size(0)):\n",
    "            lengths = []\n",
    "            \n",
    "            for decomposition_length in decomposition_lengths:\n",
    "                lengths.append(decomposition_length[i])\n",
    "            \n",
    "            packed_sequence = pack_padded_sequence(to_predict[i], torch.tensor(lengths).cpu(), batch_first=True, enforce_sorted=False)\n",
    "            packed_output, _ = self.embedding(packed_sequence)\n",
    "            padded_output, padded_output_lengths = pad_packed_sequence(packed_output, batch_first=True)\n",
    "            \n",
    "            word_context = torch.zeros(padded_output.size(0), padded_output.size(2)).to(device)\n",
    "            for j in range(batch_size):\n",
    "                word_context[j] = padded_output[j, padded_output_lengths[j] - 1, :]\n",
    "            \n",
    "            projection_output = self.embdding_projection(word_context)\n",
    "            \n",
    "            embeddings[i] = projection_output\n",
    "        \n",
    "        embeddings = embeddings.transpose(0, 1)\n",
    "                \n",
    "        #### Encoder\n",
    "        packed_sequence = pack_padded_sequence(embeddings, lengths_tensor.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, decoder_hidden = self.encoder(packed_sequence)\n",
    "        \n",
    "        #### Decoder\n",
    "        decoder_input = torch.zeros(1, batch_size, 1).to(device).new_full((1, batch_size, 1), -1)\n",
    "        max_length = lengths_tensor[0].item()\n",
    "        prediction_sequence = torch.zeros(max_length + 1, batch_size, 4).to(device)\n",
    "        decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "        decoder_output = self.decoder_projection(decoder_output[0])\n",
    "        \n",
    "        prediction_sequence[0] = decoder_output\n",
    "        _, decoder_input = decoder_output.topk(1)\n",
    "        \n",
    "        if target is not None and random.random() < 0.5:\n",
    "            target = target.transpose(0, 1)\n",
    "            for idx in range(max_length):\n",
    "                decoder_input = target[idx].view(1, batch_size, 1).float()\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "                decoder_output = self.decoder_projection(decoder_output[0])\n",
    "                prediction_sequence[idx + 1] = decoder_output\n",
    "        else:\n",
    "            for idx in range(max_length):\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input.view(1, batch_size, 1).float(), decoder_hidden)\n",
    "                decoder_output = self.decoder_projection(decoder_output[0])\n",
    "                prediction_sequence[idx + 1] = decoder_output\n",
    "                _, decoder_input = decoder_output.topk(1)\n",
    "                \n",
    "        return prediction_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "handy-discipline",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:35.857287Z",
     "start_time": "2021-03-14T13:43:35.855326Z"
    }
   },
   "outputs": [],
   "source": [
    "addresses_to_parse = [\"3 jersey road, un 28 nsw 2064\", \"fast ave\", \"hello ave\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "opened-killing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:36.661030Z",
     "start_time": "2021-03-14T13:43:36.065994Z"
    }
   },
   "outputs": [],
   "source": [
    "emb_model = BPEmb(lang=\"multi\", vs=100000, dim=300)\n",
    "vectorizer = BPEmbVectorizer(embeddings_model=emb_model)\n",
    "model = Seq2SeqModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "gross-chain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:36.664529Z",
     "start_time": "2021-03-14T13:43:36.661970Z"
    }
   },
   "outputs": [],
   "source": [
    "output = vectorizer(addresses_to_parse)\n",
    "padded_output = bpemb_data_padding(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "apart-newark",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:36.690421Z",
     "start_time": "2021-03-14T13:43:36.665363Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = model(*padded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cutting-patient",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:36.741943Z",
     "start_time": "2021-03-14T13:43:36.739822Z"
    }
   },
   "outputs": [],
   "source": [
    "tags_predictions = predictions.max(2)[1].transpose(0, 1).cpu().numpy()\n",
    "tags_predictions_prob = torch.exp(predictions.max(2)[0]).transpose(0, 1).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "certain-radius",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:36.991309Z",
     "start_time": "2021-03-14T13:43:36.988931Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "statutory-stadium",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:37.197724Z",
     "start_time": "2021-03-14T13:43:37.194434Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2537793 , 0.25413087, 0.25421765, 0.2542254 , 0.2542219 ,\n",
       "        0.2542237 , 0.25423124, 0.2542414 ],\n",
       "       [0.2537815 , 0.25405163, 0.2541368 , 0.25416574, 0.2541837 ,\n",
       "        0.2542014 , 0.25421923, 0.2542355 ],\n",
       "       [0.25378394, 0.2540525 , 0.25413883, 0.2541687 , 0.25418675,\n",
       "        0.25420406, 0.25422132, 0.25423703]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_predictions_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "changing-mechanism",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:37.403322Z",
     "start_time": "2021-03-14T13:43:37.394829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 jersey road, un 28 nsw 2064\n",
      "\t 3 1 0.2537793\n",
      "\t jersey 1 0.25413087\n",
      "\t road, 1 0.25421765\n",
      "\t un 1 0.2542254\n",
      "\t 28 1 0.2542219\n",
      "\t nsw 1 0.2542237\n",
      "\t 2064 1 0.25423124\n",
      "fast ave\n",
      "\t fast 1 0.2537815\n",
      "\t ave 1 0.25405163\n",
      "hello ave\n",
      "\t hello 1 0.25378394\n",
      "\t ave 1 0.2540525\n"
     ]
    }
   ],
   "source": [
    "tagged_addresses_components = []\n",
    "for address_to_parse, tags_prediction, tags_prediction_prob in zip(addresses_to_parse, tags_predictions,\n",
    "                                                                   tags_predictions_prob):\n",
    "    tagged_address_components = []\n",
    "    print(address_to_parse)\n",
    "    for word, predicted_idx_tag, tag_proba in zip(address_to_parse.split(), tags_prediction,\n",
    "                                                  tags_prediction_prob):\n",
    "        print(\"\\t\", word, predicted_idx_tag, tag_proba)\n",
    "        tag = (tags_converter(predicted_idx_tag), tag_proba)\n",
    "        tagged_address_components.append((word, tag))\n",
    "    tagged_addresses_components.append(tagged_address_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "italic-chapter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:43:37.595484Z",
     "start_time": "2021-03-14T13:43:37.591664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('3', ('Street', 0.2537793)),\n",
       "  ('jersey', ('Street', 0.25413087)),\n",
       "  ('road,', ('Street', 0.25421765)),\n",
       "  ('un', ('Street', 0.2542254)),\n",
       "  ('28', ('Street', 0.2542219)),\n",
       "  ('nsw', ('Street', 0.2542237)),\n",
       "  ('2064', ('Street', 0.25423124))],\n",
       " [('fast', ('Street', 0.2537815)), ('ave', ('Street', 0.25405163))],\n",
       " [('hello', ('Street', 0.25378394)), ('ave', ('Street', 0.2540525))]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_addresses_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-hours",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-alcohol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "julian-maldives",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "retained-python",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:44:18.058376Z",
     "start_time": "2021-03-14T13:44:18.054049Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file=TRAIN_CSV_PATH):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.df = self.df[self.df['labels'].notnull()]\n",
    "        self.df['labels'] = self.df['labels'].apply(literal_eval)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        raw_address = self.df.iloc[idx]['sanitized_raw_address']\n",
    "        POI, street = self.df.iloc[idx]['POI/street'].split('/')\n",
    "        labels = self.df.iloc[idx]['labels']\n",
    "        return raw_address, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "brief-saturday",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:44:21.268914Z",
     "start_time": "2021-03-14T13:44:18.483771Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x7fa070b691f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/fast/Workspace/shopee-street/shopee-street/.env/lib/python3.8/site-packages/tqdm/std.py\", line 1145, in __del__\n",
      "    self.close()\n",
      "  File \"/fast/Workspace/shopee-street/shopee-street/.env/lib/python3.8/site-packages/tqdm/notebook.py\", line 271, in close\n",
      "    super(tqdm_notebook, self).close()\n",
      "  File \"/fast/Workspace/shopee-street/shopee-street/.env/lib/python3.8/site-packages/tqdm/std.py\", line 1264, in close\n",
      "    if self.disable:\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disable'\n",
      "Exception ignored in: <function tqdm.__del__ at 0x7fa070b691f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/fast/Workspace/shopee-street/shopee-street/.env/lib/python3.8/site-packages/tqdm/std.py\", line 1145, in __del__\n",
      "    self.close()\n",
      "  File \"/fast/Workspace/shopee-street/shopee-street/.env/lib/python3.8/site-packages/tqdm/notebook.py\", line 271, in close\n",
      "    super(tqdm_notebook, self).close()\n",
      "  File \"/fast/Workspace/shopee-street/shopee-street/.env/lib/python3.8/site-packages/tqdm/std.py\", line 1264, in close\n",
      "    if self.disable:\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disable'\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "personalized-maryland",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:44:21.280188Z",
     "start_time": "2021-03-14T13:44:21.269901Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>id</th>\n",
       "      <th>raw_address</th>\n",
       "      <th>POI/street</th>\n",
       "      <th>sanitized_raw_address</th>\n",
       "      <th>is_clean</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4941</td>\n",
       "      <td>4941</td>\n",
       "      <td>hadi raya kre, no 29 balaraja</td>\n",
       "      <td>hadi/raya kre</td>\n",
       "      <td>hadi raya kre , no 29 balaraja</td>\n",
       "      <td>True</td>\n",
       "      <td>[PointOfInterest, Street, Street, Other, Other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>115253</td>\n",
       "      <td>115253</td>\n",
       "      <td>merak 11, no 10 cikarang utara</td>\n",
       "      <td>/merak 11</td>\n",
       "      <td>merak 11 , no 10 cikarang utara</td>\n",
       "      <td>True</td>\n",
       "      <td>[Street, Street, Other, Other, Other, Other, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>299321</td>\n",
       "      <td>299321</td>\n",
       "      <td>hotel fairmont jl asia afrika 8 gelora bung karno</td>\n",
       "      <td>bung karno/jl asia afrika</td>\n",
       "      <td>hotel fairmont jl asia afrika 8 gelora bung karno</td>\n",
       "      <td>True</td>\n",
       "      <td>[Other, Other, Street, Street, Street, Other, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>173570</td>\n",
       "      <td>173570</td>\n",
       "      <td>kar anyar d, 4 karang anyar rt 15 1 sawah besar</td>\n",
       "      <td>/kar anyar d</td>\n",
       "      <td>kar anyar d , 4 karang anyar rt 15 1 sawah besar</td>\n",
       "      <td>True</td>\n",
       "      <td>[Street, Street, Street, Other, Other, Other, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>30862</td>\n",
       "      <td>30862</td>\n",
       "      <td>roban gg. bakti 135 singkawang tengah</td>\n",
       "      <td>/gg. bakti</td>\n",
       "      <td>roban gg. bakti 135 singkawang tengah</td>\n",
       "      <td>True</td>\n",
       "      <td>[Other, Street, Street, Other, Other, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239995</th>\n",
       "      <td>239995</td>\n",
       "      <td>239995</td>\n",
       "      <td>5274</td>\n",
       "      <td>5274</td>\n",
       "      <td>cata xii,</td>\n",
       "      <td>/cata xii</td>\n",
       "      <td>cata xii ,</td>\n",
       "      <td>True</td>\n",
       "      <td>[Street, Street, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239996</th>\n",
       "      <td>239996</td>\n",
       "      <td>239996</td>\n",
       "      <td>161682</td>\n",
       "      <td>161682</td>\n",
       "      <td>nga jaya 27 1 pucang sewu gubeng</td>\n",
       "      <td>/nga jaya</td>\n",
       "      <td>nga jaya 27 1 pucang sewu gubeng</td>\n",
       "      <td>True</td>\n",
       "      <td>[Street, Street, Other, Other, Other, Other, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239997</th>\n",
       "      <td>239997</td>\n",
       "      <td>239997</td>\n",
       "      <td>28853</td>\n",
       "      <td>28853</td>\n",
       "      <td>taman ubud lest v no 21 binong curug</td>\n",
       "      <td>/taman ubud lest v</td>\n",
       "      <td>taman ubud lest v no 21 binong curug</td>\n",
       "      <td>True</td>\n",
       "      <td>[Street, Street, Street, Street, Other, Other,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239998</th>\n",
       "      <td>239998</td>\n",
       "      <td>239998</td>\n",
       "      <td>298534</td>\n",
       "      <td>298534</td>\n",
       "      <td>raya riga tanjung ganti i kelam tengah</td>\n",
       "      <td>/raya riga</td>\n",
       "      <td>raya riga tanjung ganti i kelam tengah</td>\n",
       "      <td>True</td>\n",
       "      <td>[Street, Street, Other, Other, Other, Other, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239999</th>\n",
       "      <td>239999</td>\n",
       "      <td>239999</td>\n",
       "      <td>262227</td>\n",
       "      <td>262227</td>\n",
       "      <td>gg. gad iii 48 pisangan timur rt 4 14 pulo gadung</td>\n",
       "      <td>/</td>\n",
       "      <td>gg. gad iii 48 pisangan timur rt 4 14 pulo gadung</td>\n",
       "      <td>True</td>\n",
       "      <td>[Other, Other, Other, Other, Other, Other, Oth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188882 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1      id  \\\n",
       "0                0             0            4941    4941   \n",
       "2                2             2          115253  115253   \n",
       "3                3             3          299321  299321   \n",
       "4                4             4          173570  173570   \n",
       "5                5             5           30862   30862   \n",
       "...            ...           ...             ...     ...   \n",
       "239995      239995        239995            5274    5274   \n",
       "239996      239996        239996          161682  161682   \n",
       "239997      239997        239997           28853   28853   \n",
       "239998      239998        239998          298534  298534   \n",
       "239999      239999        239999          262227  262227   \n",
       "\n",
       "                                              raw_address  \\\n",
       "0                           hadi raya kre, no 29 balaraja   \n",
       "2                          merak 11, no 10 cikarang utara   \n",
       "3       hotel fairmont jl asia afrika 8 gelora bung karno   \n",
       "4         kar anyar d, 4 karang anyar rt 15 1 sawah besar   \n",
       "5                   roban gg. bakti 135 singkawang tengah   \n",
       "...                                                   ...   \n",
       "239995                                          cata xii,   \n",
       "239996                   nga jaya 27 1 pucang sewu gubeng   \n",
       "239997               taman ubud lest v no 21 binong curug   \n",
       "239998             raya riga tanjung ganti i kelam tengah   \n",
       "239999  gg. gad iii 48 pisangan timur rt 4 14 pulo gadung   \n",
       "\n",
       "                       POI/street  \\\n",
       "0                   hadi/raya kre   \n",
       "2                       /merak 11   \n",
       "3       bung karno/jl asia afrika   \n",
       "4                    /kar anyar d   \n",
       "5                      /gg. bakti   \n",
       "...                           ...   \n",
       "239995                  /cata xii   \n",
       "239996                  /nga jaya   \n",
       "239997         /taman ubud lest v   \n",
       "239998                 /raya riga   \n",
       "239999                          /   \n",
       "\n",
       "                                    sanitized_raw_address  is_clean  \\\n",
       "0                          hadi raya kre , no 29 balaraja      True   \n",
       "2                         merak 11 , no 10 cikarang utara      True   \n",
       "3       hotel fairmont jl asia afrika 8 gelora bung karno      True   \n",
       "4        kar anyar d , 4 karang anyar rt 15 1 sawah besar      True   \n",
       "5                   roban gg. bakti 135 singkawang tengah      True   \n",
       "...                                                   ...       ...   \n",
       "239995                                         cata xii ,      True   \n",
       "239996                   nga jaya 27 1 pucang sewu gubeng      True   \n",
       "239997               taman ubud lest v no 21 binong curug      True   \n",
       "239998             raya riga tanjung ganti i kelam tengah      True   \n",
       "239999  gg. gad iii 48 pisangan timur rt 4 14 pulo gadung      True   \n",
       "\n",
       "                                                   labels  \n",
       "0       [PointOfInterest, Street, Street, Other, Other...  \n",
       "2       [Street, Street, Other, Other, Other, Other, O...  \n",
       "3       [Other, Other, Street, Street, Street, Other, ...  \n",
       "4       [Street, Street, Street, Other, Other, Other, ...  \n",
       "5            [Other, Street, Street, Other, Other, Other]  \n",
       "...                                                   ...  \n",
       "239995                            [Street, Street, Other]  \n",
       "239996  [Street, Street, Other, Other, Other, Other, O...  \n",
       "239997  [Street, Street, Street, Street, Other, Other,...  \n",
       "239998  [Street, Street, Other, Other, Other, Other, O...  \n",
       "239999  [Other, Other, Other, Other, Other, Other, Oth...  \n",
       "\n",
       "[188882 rows x 9 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-broadway",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "italian-illustration",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:44:21.286512Z",
     "start_time": "2021-03-14T13:44:21.281240Z"
    }
   },
   "outputs": [],
   "source": [
    "test_addresses = [\n",
    "    [\"50 Hello ave\", [\"Other\", \"Other\", \"Other\"]], \n",
    "    [\"SS road\", [\"Other\", \"Other\"]],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "oriented-evanescence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:44:21.289289Z",
     "start_time": "2021-03-14T13:44:21.287302Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = BPEmbVectorizer(embeddings_model=emb_model)\n",
    "tags_vectorizer = TagsConverter(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "tutorial-cutting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:44:21.291933Z",
     "start_time": "2021-03-14T13:44:21.289924Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "import pprint\n",
    "numpy.set_printoptions(threshold=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "white-cinema",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:44:21.295094Z",
     "start_time": "2021-03-14T13:44:21.292692Z"
    }
   },
   "outputs": [],
   "source": [
    "input_sequence = []\n",
    "target_sequence = []\n",
    "\n",
    "input_sequence.extend(vectorizer([address[0] for address in test_addresses]))\n",
    "for address in test_addresses:\n",
    "    target_tmp = [tags_vectorizer(target) for target in address[1]]\n",
    "    target_tmp.append(tags_vectorizer(\"EOS\"))\n",
    "    target_sequence.append(target_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "domestic-metro",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:44:21.299959Z",
     "start_time": "2021-03-14T13:44:21.295724Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[array([-0.032396, -0.051103,  0.449281, ...,  0.354258, -0.630191,\n",
       "            0.640046], dtype=float32),\n",
       "    array([0., 0., 0., ..., 0., 0., 0.])],\n",
       "   [array([ 0.119792, -0.087593, -0.366256, ..., -0.126352,  0.036049,\n",
       "            0.363969], dtype=float32),\n",
       "    array([ 0.302875, -0.092815, -0.317463, ...,  0.52216 , -0.115126,\n",
       "            0.237173], dtype=float32)],\n",
       "   [array([ 0.271623, -0.318372,  0.468792, ...,  0.548052,  0.273256,\n",
       "           -0.513469], dtype=float32),\n",
       "    array([0., 0., 0., ..., 0., 0., 0.])]],\n",
       "  [1, 2, 1]),\n",
       " ([[array([-0.126823,  0.425704,  0.154299, ...,  0.366716,  0.07786 ,\n",
       "            0.562716], dtype=float32),\n",
       "    array([0., 0., 0., ..., 0., 0., 0.])],\n",
       "   [array([-0.147449,  0.12949 , -0.107977, ...,  0.101064,  0.264715,\n",
       "            0.098076], dtype=float32),\n",
       "    array([0., 0., 0., ..., 0., 0., 0.])]],\n",
       "  [1, 1])]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "recreational-offering",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:44:21.303259Z",
     "start_time": "2021-03-14T13:44:21.301050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 2, 2, 3], [2, 2, 3]]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-apartment",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "intended-sentence",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:45:12.158461Z",
     "start_time": "2021-03-14T13:45:12.152534Z"
    }
   },
   "outputs": [],
   "source": [
    "def _convert_bpemb_sequence_to_tensor(batch):\n",
    "    \"\"\"\n",
    "    Sort and convert a BPEmb sequence into a tensor with target element\n",
    "    \"\"\"\n",
    "    sorted_batch = sorted(batch, key=lambda x: len(x[0][1]), reverse=True)\n",
    "    return zip(*[(torch.tensor(vectors), word_decomposition_len, torch.tensor(target_vectors), len(vectors))\n",
    "                 for (vectors, word_decomposition_len), target_vectors in sorted_batch])\n",
    "\n",
    "def bpemb_data_padding_with_target(batch: List[Tuple], padding_value=-100) -> Tuple:\n",
    "    \"\"\"\n",
    "    Function that add padding to the sequences and to the decomposition lengths so all can have the same length as\n",
    "    the longest one.\n",
    "    Args:\n",
    "        batch (list[tuple]): The list of vectorize tupled batch data where the first element is the address embeddings\n",
    "            and the second is the word decomposition lengths.\n",
    "    Returns:\n",
    "        A tuple ((``x``, ``y`` , ``z``), ``w``). The element ``x`` is a tensor of padded word vectors,\n",
    "        ``y`` is the padded decomposition lengths, ``z`` is the original lengths of the sequences before padding, and\n",
    "        ``w`` is a tensor of padded target idx.\n",
    "    \"\"\"\n",
    "\n",
    "    sequences_vectors, decomp_len, target_vectors, lengths = _convert_bpemb_sequence_to_tensor(batch)\n",
    "\n",
    "    lengths = torch.tensor(lengths)\n",
    "\n",
    "    padded_sequences_vectors = pad_sequence(sequences_vectors, batch_first=True, padding_value=padding_value)\n",
    "    padded_target_vectors = pad_sequence(target_vectors, batch_first=True, padding_value=padding_value)\n",
    "\n",
    "    # pad decomposition length\n",
    "    max_sequence_length = lengths.max().item()\n",
    "    for decomposition_length in decomp_len:\n",
    "        if len(decomposition_length) < max_sequence_length:\n",
    "            decomposition_length.extend([1] * (max_sequence_length - len(decomposition_length)))\n",
    "\n",
    "    return (padded_sequences_vectors, list(decomp_len), lengths), padded_target_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "active-marking",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:45:12.365221Z",
     "start_time": "2021-03-14T13:45:12.363166Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "concerned-reflection",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:45:12.554536Z",
     "start_time": "2021-03-14T13:45:12.550969Z"
    }
   },
   "outputs": [],
   "source": [
    "def collate_fn_train(batch_pairs):\n",
    "    input_sequence = []\n",
    "    target_sequence = []\n",
    "\n",
    "    input_sequence.extend(vectorizer([address[0] for address in batch_pairs]))\n",
    "    for address in batch_pairs:\n",
    "        target_tmp = [tags_vectorizer(target) for target in address[1]]\n",
    "        target_tmp.append(tags_vectorizer(\"EOS\"))\n",
    "        target_sequence.append(target_tmp)\n",
    "        \n",
    "    raw = [address[0] for address in batch_pairs]\n",
    "    return raw, zip(input_sequence, target_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "atmospheric-teaching",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:47:03.562184Z",
     "start_time": "2021-03-14T13:47:03.559923Z"
    }
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=32, collate_fn=collate_fn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ranging-williams",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:47:04.303780Z",
     "start_time": "2021-03-14T13:47:04.301656Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "brave-animation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T14:11:14.803685Z",
     "start_time": "2021-03-14T14:11:14.733566Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Seq2SeqModel().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "loss_fn = nn.NLLLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "recent-hospital",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T14:11:15.304371Z",
     "start_time": "2021-03-14T14:11:15.301851Z"
    }
   },
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-timber",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-14T14:11:34.327Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ec41adcd224231887be52c65cfe849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5903 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pasar enjo lantai 2 no a.l01.bks.123 [('pasar', 'Other', 'Other'), ('enjo', 'Other', 'Street'), ('lantai', 'Other', 'Street'), ('2', 'Other', 'Street'), ('no', 'Other', 'Street'), ('a.l01.bks.123', 'Other', 'Other')]\n",
      "mig ii 1 40534 cimahi selatan [('mig', 'Other', 'Other'), ('ii', 'Other', 'Other'), ('1', 'Other', 'Other'), ('40534', 'Other', 'Other'), ('cimahi', 'Other', 'Other'), ('selatan', 'Other', 'PointOfInterest')]\n",
      "kedai mie kdl , kapas kram [('kedai', 'Other', 'PointOfInterest'), ('mie', 'Other', 'PointOfInterest'), ('kdl', 'Other', 'Other'), (',', 'Other', 'Other'), ('kapas', 'Other', 'Other'), ('kram', 'Other', 'Other')]\n",
      "kademangan komp batan indah setu [('kademangan', 'Other', 'Other'), ('komp', 'Other', 'Other'), ('batan', 'Other', 'Street'), ('indah', 'Other', 'Street'), ('setu', 'Other', 'Street')]\n",
      "lowokwaru kaliu 22 a lowokwaru [('lowokwaru', 'Other', 'Other'), ('kaliu', 'Other', 'Other'), ('22', 'Other', 'Other'), ('a', 'Other', 'PointOfInterest'), ('lowokwaru', 'Other', 'PointOfInterest')]\n",
      "puc raya , 5 8 banyumanik [('puc', 'Other', 'PointOfInterest'), ('raya', 'Other', 'PointOfInterest'), (',', 'Other', 'Other'), ('5', 'Other', 'Other'), ('8', 'Other', 'Other'), ('banyumanik', 'Other', 'Other')]\n",
      "raya boj cilimus [('raya', 'Other', 'Other'), ('boj', 'Other', 'Other'), ('cilimus', 'Other', 'Other')]\n",
      "semanan dha griya vi 23 rt 7 12 11850 kalideres [('semanan', 'Other', 'PointOfInterest'), ('dha', 'Other', 'PointOfInterest'), ('griya', 'Other', 'PointOfInterest'), ('vi', 'Other', 'Other'), ('23', 'Other', 'Other'), ('rt', 'Other', 'Other'), ('7', 'Other', 'Other'), ('12', 'Other', 'Street'), ('11850', 'Other', 'Street'), ('kalideres', 'Other', 'Street')]\n",
      "tenggu wetan , no 28 8 wonokusumo kel. semampir [('tenggu', 'Other', 'Other'), ('wetan', 'Other', 'Street'), (',', 'Other', 'Street'), ('no', 'Other', 'Street'), ('28', 'Other', 'Other'), ('8', 'Other', 'Other'), ('wonokusumo', 'Other', 'Other'), ('kel.', 'Other', 'Other'), ('semampir', 'Other', 'Other')]\n",
      "rsu [('rsu', 'Other', 'Other')]\n",
      "kelor utama , [('kelor', 'Other', 'Other'), ('utama', 'Other', 'Other'), (',', 'Other', 'Other')]\n",
      "jl. ujung hara nain rt 12 15 bekasi utara [('jl.', 'Other', 'Other'), ('ujung', 'Other', 'Other'), ('hara', 'Other', 'Other'), ('nain', 'Other', 'Street'), ('rt', 'Other', 'Street'), ('12', 'Other', 'PointOfInterest'), ('15', 'Other', 'PointOfInterest'), ('bekasi', 'Other', 'PointOfInterest'), ('utara', 'Other', 'Other')]\n",
      "pakis sid pakis sawahan [('pakis', 'Street', 'Other'), ('sid', 'Other', 'Other'), ('pakis', 'Other', 'Other'), ('sawahan', 'Other', 'Street')]\n",
      "halte summarecon bekasi [('halte', 'Street', 'PointOfInterest'), ('summarecon', 'Other', 'PointOfInterest'), ('bekasi', 'Other', 'PointOfInterest')]\n",
      "de'wang art , raden fatah , selebar [(\"de'wang\", 'Street', 'PointOfInterest'), ('art', 'Other', 'PointOfInterest'), (',', 'Other', 'Other'), ('raden', 'Other', 'Other'), ('fatah', 'Other', 'Other'), (',', 'Other', 'Other'), ('selebar', 'Other', 'Other')]\n",
      "paradise resort the bay c5 26 jln aria putra ciputat [('paradise', 'Street', 'PointOfInterest'), ('resort', 'Other', 'PointOfInterest'), ('the', 'Other', 'PointOfInterest'), ('bay', 'Other', 'Other'), ('c5', 'Other', 'Other'), ('26', 'Other', 'Other'), ('jln', 'Other', 'Other'), ('aria', 'Other', 'Other'), ('putra', 'Other', 'Other'), ('ciputat', 'Other', 'Other')]\n",
      "pak ono , 83581 praya timur [('pak', 'Street', 'Other'), ('ono', 'Other', 'PointOfInterest'), (',', 'Other', 'PointOfInterest'), ('83581', 'Other', 'PointOfInterest'), ('praya', 'Other', 'Other'), ('timur', 'Other', 'Street')]\n",
      "trop i 45-49 tropodo waru [('trop', 'Street', 'Other'), ('i', 'Other', 'Other'), ('45-49', 'Other', 'Other'), ('tropodo', 'Other', 'Other'), ('waru', 'Other', 'Street')]\n",
      "kedaung kali angke daan mogot rt 11 2 11710 cengkareng [('kedaung', 'Street', 'Street'), ('kali', 'Other', 'Street'), ('angke', 'Other', 'Street'), ('daan', 'Other', 'Street'), ('mogot', 'Other', 'Other'), ('rt', 'Other', 'Other'), ('11', 'Other', 'Other'), ('2', 'Other', 'Other'), ('11710', 'Other', 'Other'), ('cengkareng', 'Other', 'Other')]\n",
      "komp damai jalur 2 , [('komp', 'Street', 'PointOfInterest'), ('damai', 'Other', 'PointOfInterest'), ('jalur', 'Other', 'Other'), ('2', 'Other', 'Other'), (',', 'Other', 'Other')]\n",
      "sempakata bunga sedap malam xviii 16 20131 medan selayang [('sempakata', 'Street', 'Other'), ('bunga', 'Other', 'Other'), ('sedap', 'Other', 'Other'), ('malam', 'Other', 'Other'), ('xviii', 'Other', 'Other'), ('16', 'Other', 'Other'), ('20131', 'Other', 'Other'), ('medan', 'Other', 'Other'), ('selayang', 'Other', 'Other')]\n",
      "let supr , kepandean kel. [('let', 'Street', 'Other'), ('supr', 'Other', 'Other'), (',', 'Other', 'Other'), ('kepandean', 'Other', 'Street'), ('kel.', 'Other', 'Street')]\n",
      "rejowinangun nyi adi sari 221 [('rejowinangun', 'Street', 'Street'), ('nyi', 'Other', 'Street'), ('adi', 'Other', 'Street'), ('sari', 'Other', 'PointOfInterest'), ('221', 'Other', 'PointOfInterest')]\n",
      "toko lukas rajagukguk , gar [('toko', 'Street', 'Other'), ('lukas', 'Other', 'Other'), ('rajagukguk', 'Other', 'Other'), (',', 'Other', 'Other'), ('gar', 'Other', 'Other')]\n",
      "jend a yani , [('jend', 'Street', 'Other'), ('a', 'Other', 'Other'), ('yani', 'Other', 'Other'), (',', 'Other', 'Other')]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for idx, batch in enumerate(tqdm(data_loader)):\n",
    "        raw, batch = batch\n",
    "        padded_input, padded_target = bpemb_data_padding_with_target(batch)\n",
    "        padded_input = (padded_input[0].to(device), \n",
    "                        padded_input[1], \n",
    "                        padded_input[2].to(device))\n",
    "        padded_target = padded_target.to(device)\n",
    "        model.zero_grad()\n",
    "\n",
    "        predictions = model(*padded_input, padded_target)\n",
    "        predictions = predictions.permute(1, 2, 0)\n",
    "        loss = loss_fn(predictions, padded_target)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        counter += 1\n",
    "\n",
    "        writer.add_scalar(\"Loss/train\", loss, counter)\n",
    "\n",
    "        if counter % 100 == 0:\n",
    "            TEST_IDX = 0\n",
    "            sample_raw = raw[TEST_IDX].split()\n",
    "            sample_pred = predictions[TEST_IDX].transpose(0,1).argmax(dim=1).detach().cpu().numpy()\n",
    "            sample_pred_string = [tags_converter(x) for x in sample_pred]\n",
    "            sample_target = padded_target[TEST_IDX].detach().cpu().numpy()\n",
    "            sample_target_string = [tags_converter(x) for x in sample_target]\n",
    "            compact = list(zip(sample_raw, sample_pred_string, sample_target_string))\n",
    "            print(raw[TEST_IDX], compact)\n",
    "            \n",
    "    lr_scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-exhibit",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "racial-radio",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:51:00.758027Z",
     "start_time": "2021-03-14T13:51:00.676767Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"./scl-2021-ds/valid_split.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "collective-genesis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T13:55:16.543490Z",
     "start_time": "2021-03-14T13:55:16.501342Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "occupied-tongue",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T14:03:59.148081Z",
     "start_time": "2021-03-14T14:03:59.145765Z"
    }
   },
   "outputs": [],
   "source": [
    "n_correct = 0\n",
    "n_correct_only_POI = 0\n",
    "n_correct_only_street = 0\n",
    "n_all = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize(row):\n",
    "    raw_address = row['raw_address']\n",
    "    sanitized_raw_address = raw_address.replace(',', ' ,')\n",
    "    return sanitized_raw_address\n",
    "test_data['sanitized_raw_address'] = test_data.apply(sanitize, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "convenient-captain",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T14:07:17.923985Z",
     "start_time": "2021-03-14T14:07:17.911395Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cb9053ade4468a9c7b726f3d513c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pbar = tqdm(test_data.iterrows(), total=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "naval-marking",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-14T14:11:13.977750Z",
     "start_time": "2021-03-14T14:07:18.092850Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-306c9bfcccfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mraw_address\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpadded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbpemb_data_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpadded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mtags_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fast/Workspace/shopee-street/shopee-street/.env/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-6f7ce7bf3b35>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, to_predict, decomposition_lengths, lengths_tensor, target)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mpacked_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mpacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mpadded_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_output_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_packed_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mword_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadded_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/fast/Workspace/shopee-street/shopee-street/.env/lib/python3.8/site-packages/torch/nn/utils/rnn.py\u001b[0m in \u001b[0;36mpad_packed_sequence\u001b[0;34m(sequence, batch_first, padding_value, total_length)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0munsorted_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mbatch_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatch_first\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpadded_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_select\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munsorted_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpadded_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _, row in pbar:\n",
    "    sanitized_raw_address = row['sanitized_raw_address']\n",
    "    target = row['POI/street']\n",
    "    emb = vectorizer([raw_address])\n",
    "    padded = bpemb_data_padding(emb)\n",
    "    pred = model(*padded)\n",
    "    tags_predictions = pred.max(2)[1].transpose(0, 1).cpu().numpy()[0]\n",
    "    \n",
    "    tokens = sanitized_raw_address.split()\n",
    "    pred_POI = []\n",
    "    pred_Street = []\n",
    "    for (token, pred) in zip(tokens, tags_predictions):\n",
    "        if pred == 0: \n",
    "            pred_POI.append(token)\n",
    "        elif pred == 1:\n",
    "            pred_Street.append(token)\n",
    "            \n",
    "    pred_POI = ' '.join(pred_POI)\n",
    "    pred_Street = ' '.join(pred_Street)\n",
    "    output = f'{pred_POI}/{pred_Street}'\n",
    "\n",
    "    n_correct += (output == target)\n",
    "    n_correct_only_POI += (pred_POI == target.split('/')[0])\n",
    "    n_correct_only_street += (pred_Street == target.split('/')[1])\n",
    "    n_all += 1\n",
    "    \n",
    "    acc = (n_correct / n_all)\n",
    "    acc_POI = (n_correct_only_POI / n_all)\n",
    "    acc_street = (n_correct_only_street / n_all)\n",
    "    pbar.set_description(f\"acc={acc:.3f} acc_POI={acc_POI:.3f} acc_street={acc_street:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-marsh",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}