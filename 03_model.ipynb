{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1239,
   "id": "norwegian-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "from ast import literal_eval\n",
    "from typing import Dict, Union, Any, List, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.core.multiarray import ndarray\n",
    "from tqdm.notebook import tqdm\n",
    "from bpemb import BPEmb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "metropolitan-penny",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV_PATH = './santi/deepparse_clean_only_train_split.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "id": "informative-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {\n",
    "    \"PointOfInterest\": 0,\n",
    "    \"Street\": 1,\n",
    "    \"Other\": 2,\n",
    "    \"EOS\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comparable-denver",
   "metadata": {},
   "source": [
    "## Tags Coverter\n",
    "\n",
    "`TagsCoverter` is a utility class for converting between tag ID and tag name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "worldwide-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/GRAAL-Research/deepparse/blob/0951ffa18b0838fbd536d8d607695f1667d9939a/deepparse/converter/target_converter.py\n",
    "\n",
    "class TagsConverter:\n",
    "    \"\"\"\n",
    "    Class to define logic of tag to idx conversion and vice versa.\n",
    "    Args:\n",
    "        tags_to_idx (Dict): A dictionary where the keys are the tags (e.g. StreetNumber) and the values are\n",
    "            the indexes (int) (e.g. 1).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tags_to_idx: Dict) -> None:\n",
    "        self.tags_to_idx = tags_to_idx\n",
    "        self.idx_to_tags = {v: k for k, v in tags_to_idx.items()}\n",
    "\n",
    "    def __call__(self, key: Union[str, int]) -> int:\n",
    "        \"\"\"\n",
    "        If str convert from a tag to idx and if int convert from a idx to a tag using the convert table.\n",
    "        \"\"\"\n",
    "        if isinstance(key, str):\n",
    "            return self.tags_to_idx[key]\n",
    "        return self.idx_to_tags[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "supreme-burden",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_converter = TagsConverter(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "incomplete-sculpture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'PointOfInterest')"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_converter('PointOfInterest'), tags_converter(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-mozambique",
   "metadata": {},
   "source": [
    "## Token -> Subword Embeddings\n",
    "\n",
    "`BPEmb` is a way to convert between string to subword embeddings. In this model, we have $10^5$ subwords and each subword has an embedding of dimension 300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "social-agency",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = BPEmb(lang=\"multi\", vs=100000, dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "coupled-appeal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁h', 'ello', '▁ave', '▁fast']"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.encode(\"Hello ave fast\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "specific-rescue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35, 3333]"
      ]
     },
     "execution_count": 769,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.encode_ids(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "fleet-cassette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 300)"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_model.embed(\"hello\").shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-annex",
   "metadata": {},
   "source": [
    "## Vectorizer\n",
    "\n",
    "`BPEmbVectorizer` is a class for converting a list of addresses into nested array subword embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "french-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/GRAAL-Research/deepparse/blob/0951ffa18b0838fbd536d8d607695f1667d9939a/deepparse/vectorizer/bpemb_vectorizer.py#L9\n",
    "\n",
    "class BPEmbVectorizer:\n",
    "    \"\"\"\n",
    "    BPEmb vectorizer to convert an address into BPEmb embedding where each word is decomposed into subword units that\n",
    "    are in turn embedded as a vector\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embeddings_model: Any) -> None:\n",
    "        self.embeddings_model = embeddings_model\n",
    "        self.padding_value = 0\n",
    "\n",
    "    def __call__(self, addresses: List[str]) -> List[Tuple]:\n",
    "        \"\"\"\n",
    "        Method to vectorizer addresses.\n",
    "        Args:\n",
    "            addresses (list[str]): The addresses to vectorize.\n",
    "        Return:\n",
    "            A tuple of the addresses elements (components) embedding vectosr and the word decomposition lengths.\n",
    "        \"\"\"\n",
    "        self._max_length = 0\n",
    "        batch = [self._vectorize_sequence(address) for address in addresses]\n",
    "        self._decomposed_sequence_padding(batch)\n",
    "        return batch\n",
    "\n",
    "    def _vectorize_sequence(self, address: str) -> Tuple[List, List]:\n",
    "        \"\"\"\n",
    "        Method to vectorize the address.\n",
    "        Args:\n",
    "            address (str): Address to vectorize using BPEmb.\n",
    "        Return:\n",
    "            A tuple of list of word vector and the word decomposition lengths.\n",
    "        \"\"\"\n",
    "        input_sequence = []\n",
    "        word_decomposition_lengths = []\n",
    "#         address = address.replace(\",\", \"\")  # see issue 56 https://github.com/GRAAL-Research/deepparse/issues/56\n",
    "        for word in address.split():\n",
    "            bpe_decomposition = self.embeddings_model.embed(word)\n",
    "            word_decomposition_lengths.append(len(bpe_decomposition))\n",
    "            input_sequence.append(list(bpe_decomposition))\n",
    "\n",
    "        self._max_length = max(self._max_length, max(word_decomposition_lengths))\n",
    "\n",
    "        return input_sequence, word_decomposition_lengths\n",
    "\n",
    "    def _decomposed_sequence_padding(self, batch: List[Tuple]) -> None:\n",
    "        \"\"\"\n",
    "        Method to add padding to the decomposed sequence.\n",
    "        \"\"\"\n",
    "        for decomposed_sequence, _ in batch:\n",
    "            for decomposition in decomposed_sequence:\n",
    "                if len(decomposition) != self._max_length:\n",
    "                    decomposition.extend([np.ones(self.embeddings_model.dim) * [self.padding_value]] *\n",
    "                                         (self._max_length - len(decomposition)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "verified-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = BPEmbVectorizer(embeddings_model=emb_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "amended-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = vectorizer([\"Hello ave fast\"])\n",
    "# output[0] => \"Hello ave\"\n",
    "# output[0][0] => embeddings\n",
    "#     output[0][0][0] => Hello\n",
    "#     output[0][0][1] => Ave\n",
    "# output[0][1] => length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "suspected-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 774,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "id": "worth-savannah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 1]"
      ]
     },
     "execution_count": 775,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-delicious",
   "metadata": {},
   "source": [
    "## Padding to torch Tensor\n",
    "\n",
    "Note that different addresses may have different number of subwords. To handle this, we pad the tensor with zeros. `bpemb_data_padding` handles the padding and converts the nested array of subwords to `torch.Tensor` of padded subword embedding and its length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "thick-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/GRAAL-Research/deepparse/blob/0951ffa18b0838fbd536d8d607695f1667d9939a/deepparse/converter/data_padding.py#L36\n",
    "\n",
    "def bpemb_data_padding(batch: List[Tuple], padding_value=-100) -> Tuple:\n",
    "    \"\"\"\n",
    "    Function that add padding to the sequences and to the decomposition lengths so all can have the same length as\n",
    "    the longest one.\n",
    "    Args:\n",
    "        batch (list[tuple]): The list of vectorize tupled batch data where the first element is the address embeddings\n",
    "            and the second is the word decomposition lengths.\n",
    "    Returns:\n",
    "        A tuple (``x``, ``y``, ``z``). The element ``x`` is a tensor of padded word vectors, ``y`` is the padded\n",
    "        decomposition lengths, and ``z`` is the original lengths of the sequences before padding.\n",
    "    \"\"\"\n",
    "\n",
    "    sequences_vectors, decomp_len, lengths = zip(\n",
    "        *[(torch.tensor(vectors), word_decomposition_len, len(vectors))\n",
    "          for vectors, word_decomposition_len in sorted(batch, key=lambda x: len(x[0]), reverse=True)])\n",
    "\n",
    "    lengths = torch.tensor(lengths)\n",
    "\n",
    "    padded_sequences_vectors = pad_sequence(sequences_vectors, batch_first=True, padding_value=padding_value)\n",
    "\n",
    "    # pad decomposition length\n",
    "    max_sequence_length = lengths.max().item()\n",
    "    for decomposition_length in decomp_len:\n",
    "        if len(decomposition_length) < max_sequence_length:\n",
    "            decomposition_length.extend([1] * (max_sequence_length - len(decomposition_length)))\n",
    "\n",
    "    return padded_sequences_vectors, list(decomp_len), lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "compound-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_output = bpemb_data_padding(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "phantom-confidentiality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.1198, -0.0876, -0.3663,  ..., -0.1264,  0.0360,  0.3640],\n",
       "           [ 0.3029, -0.0928, -0.3175,  ...,  0.5222, -0.1151,  0.2372]],\n",
       " \n",
       "          [[ 0.2716, -0.3184,  0.4688,  ...,  0.5481,  0.2733, -0.5135],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "          [[-0.0346, -0.1021, -0.7138,  ..., -0.5223, -0.0465, -0.0476],\n",
       "           [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "        dtype=torch.float64),\n",
       " [[2, 1, 1]],\n",
       " tensor([3]))"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-marijuana",
   "metadata": {},
   "source": [
    "## Seq2Seq Model\n",
    "\n",
    "Here is a simple model modified from deepparse. It takes a sequence of subword embeddings and outputs tagging probability for each subword.\n",
    "\n",
    "For example, the string `\"Hello ave fast\"` has 4 subwords `['▁h', 'ello', '▁ave', '▁fast']`. The model outputs a tensor of shape `(n_subwords, 4)` indicating the logits of the particular subword having certain tag. Currently, we have 4 tags, as follows: POI, Street Name, Others, End-of-String.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "id": "danish-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adapted from https://github.com/GRAAL-Research/deepparse/blob/0951ffa18b0838fbd536d8d607695f1667d9939a/deepparse/network/bpemb_seq2seq.py#L9\n",
    "\n",
    "class Seq2SeqModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding network\n",
    "        self.embedding_input_size = 300\n",
    "        self.embedding_hidden_size = 300\n",
    "        self.embedding_num_layers = 1\n",
    "        self.embedding = nn.LSTM(self.embedding_input_size, \n",
    "                                 self.embedding_hidden_size, \n",
    "                                 num_layers=self.embedding_num_layers,\n",
    "                                 batch_first=True,\n",
    "                                 bidirectional=True)\n",
    "\n",
    "        self.embedding_projection_size = 300\n",
    "        self.embdding_projection = nn.Linear(2 * self.embedding_hidden_size, self.embedding_projection_size)\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder_input_size = 300\n",
    "        self.encoder_hidden_size = 1024\n",
    "        self.encoder_num_layers = 1\n",
    "        self.encoder = nn.LSTM(self.encoder_input_size, \n",
    "                               self.encoder_hidden_size,\n",
    "                               num_layers=self.encoder_num_layers, \n",
    "                               batch_first=True)\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder_input_size = 1\n",
    "        self.decoder_hidden_size = 1024\n",
    "        self.decoder_num_layers = 1\n",
    "        self.decoder = nn.LSTM(self.decoder_input_size, \n",
    "                               self.decoder_hidden_size,\n",
    "                               num_layers=self.decoder_num_layers)\n",
    "        \n",
    "        self.decoder_projection_output_size = 4\n",
    "        self.decoder_projection = []\n",
    "        self.decoder_projection.append(nn.Linear(self.decoder_hidden_size, self.decoder_projection_output_size))\n",
    "        self.decoder_projection.append(nn.LogSoftmax(dim=1))\n",
    "        self.decoder_projection = nn.Sequential(*self.decoder_projection)\n",
    "        \n",
    "    def forward(self, \n",
    "                to_predict: torch.Tensor, \n",
    "                decomposition_lengths: List, \n",
    "                lengths_tensor: torch.Tensor,\n",
    "                target: Union[torch.Tensor, None] = None) -> torch.Tensor:\n",
    "        device = to_predict.device\n",
    "        batch_size = to_predict.size(0)\n",
    "        \n",
    "        #### Get embedded output\n",
    "        embeddings = torch.zeros(to_predict.size(1), to_predict.size(0), to_predict.size(3)).to(device)\n",
    "        to_predict = to_predict.transpose(0, 1).float()\n",
    "        \n",
    "        for i in range(to_predict.size(0)):\n",
    "            lengths = []\n",
    "            \n",
    "            for decomposition_length in decomposition_lengths:\n",
    "                lengths.append(decomposition_length[i])\n",
    "            \n",
    "            packed_sequence = pack_padded_sequence(to_predict[i], torch.tensor(lengths).cpu(), batch_first=True, enforce_sorted=False)\n",
    "            packed_output, _ = self.embedding(packed_sequence)\n",
    "            padded_output, padded_output_lengths = pad_packed_sequence(packed_output, batch_first=True)\n",
    "            \n",
    "            word_context = torch.zeros(padded_output.size(0), padded_output.size(2)).to(device)\n",
    "            for j in range(batch_size):\n",
    "                word_context[j] = padded_output[j, padded_output_lengths[j] - 1, :]\n",
    "            \n",
    "            projection_output = self.embdding_projection(word_context)\n",
    "            \n",
    "            embeddings[i] = projection_output\n",
    "        \n",
    "        embeddings = embeddings.transpose(0, 1)\n",
    "                \n",
    "        #### Encoder\n",
    "        packed_sequence = pack_padded_sequence(embeddings, lengths_tensor.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        _, decoder_hidden = self.encoder(packed_sequence)\n",
    "        \n",
    "        #### Decoder\n",
    "        decoder_input = torch.zeros(1, batch_size, 1).to(device).new_full((1, batch_size, 1), -1)\n",
    "        max_length = lengths_tensor[0].item()\n",
    "        prediction_sequence = torch.zeros(max_length + 1, batch_size, 4).to(device)\n",
    "        decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "        decoder_output = self.decoder_projection(decoder_output[0])\n",
    "        \n",
    "        prediction_sequence[0] = decoder_output\n",
    "        _, decoder_input = decoder_output.topk(1)\n",
    "        \n",
    "        if target is not None and random.random() < 0.5:\n",
    "            target = target.transpose(0, 1)\n",
    "            for idx in range(max_length):\n",
    "                decoder_input = target[idx].view(1, batch_size, 1).float()\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "                decoder_output = self.decoder_projection(decoder_output[0])\n",
    "                prediction_sequence[idx + 1] = decoder_output\n",
    "        else:\n",
    "            for idx in range(max_length):\n",
    "                decoder_output, decoder_hidden = self.decoder(decoder_input.view(1, batch_size, 1).float(), decoder_hidden)\n",
    "                decoder_output = self.decoder_projection(decoder_output[0])\n",
    "                prediction_sequence[idx + 1] = decoder_output\n",
    "                _, decoder_input = decoder_output.topk(1)\n",
    "                \n",
    "        return prediction_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "id": "handy-discipline",
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses_to_parse = [\"3 jersey road, un 28 nsw 2064\", \"fast ave\", \"hello ave\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1210,
   "id": "opened-killing",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = BPEmb(lang=\"multi\", vs=100000, dim=300)\n",
    "vectorizer = BPEmbVectorizer(embeddings_model=emb_model)\n",
    "model = Seq2SeqModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "id": "gross-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = vectorizer(addresses_to_parse)\n",
    "padded_output = bpemb_data_padding(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1212,
   "id": "apart-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(*padded_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "id": "cutting-patient",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_predictions = predictions.max(2)[1].transpose(0, 1).cpu().numpy()\n",
    "tags_predictions_prob = torch.exp(predictions.max(2)[0]).transpose(0, 1).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "id": "certain-radius",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3, 4])"
      ]
     },
     "execution_count": 1214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "id": "statutory-stadium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2519082 , 0.25286847, 0.25355572, 0.25399396, 0.25425678,\n",
       "        0.25440928, 0.25449604, 0.2545451 ],\n",
       "       [0.2520041 , 0.25292265, 0.25359643, 0.2540266 , 0.254282  ,\n",
       "        0.25442755, 0.25450867, 0.25455344],\n",
       "       [0.25184074, 0.25283876, 0.2535532 , 0.25400448, 0.2542707 ,\n",
       "        0.25442186, 0.2545058 , 0.25455204]], dtype=float32)"
      ]
     },
     "execution_count": 1215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_predictions_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "id": "changing-mechanism",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 jersey road, un 28 nsw 2064\n",
      "\t 3 0 0.2519082\n",
      "\t jersey 0 0.25286847\n",
      "\t road, 0 0.25355572\n",
      "\t un 0 0.25399396\n",
      "\t 28 0 0.25425678\n",
      "\t nsw 0 0.25440928\n",
      "\t 2064 0 0.25449604\n",
      "fast ave\n",
      "\t fast 0 0.2520041\n",
      "\t ave 0 0.25292265\n",
      "hello ave\n",
      "\t hello 0 0.25184074\n",
      "\t ave 0 0.25283876\n"
     ]
    }
   ],
   "source": [
    "tagged_addresses_components = []\n",
    "for address_to_parse, tags_prediction, tags_prediction_prob in zip(addresses_to_parse, tags_predictions,\n",
    "                                                                   tags_predictions_prob):\n",
    "    tagged_address_components = []\n",
    "    print(address_to_parse)\n",
    "    for word, predicted_idx_tag, tag_proba in zip(address_to_parse.split(), tags_prediction,\n",
    "                                                  tags_prediction_prob):\n",
    "        print(\"\\t\", word, predicted_idx_tag, tag_proba)\n",
    "        tag = (tags_converter(predicted_idx_tag), tag_proba)\n",
    "        tagged_address_components.append((word, tag))\n",
    "    tagged_addresses_components.append(tagged_address_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "id": "italic-chapter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('3', ('PointOfInterest', 0.2519082)),\n",
       "  ('jersey', ('PointOfInterest', 0.25286847)),\n",
       "  ('road,', ('PointOfInterest', 0.25355572)),\n",
       "  ('un', ('PointOfInterest', 0.25399396)),\n",
       "  ('28', ('PointOfInterest', 0.25425678)),\n",
       "  ('nsw', ('PointOfInterest', 0.25440928)),\n",
       "  ('2064', ('PointOfInterest', 0.25449604))],\n",
       " [('fast', ('PointOfInterest', 0.2520041)),\n",
       "  ('ave', ('PointOfInterest', 0.25292265))],\n",
       " [('hello', ('PointOfInterest', 0.25184074)),\n",
       "  ('ave', ('PointOfInterest', 0.25283876))]]"
      ]
     },
     "execution_count": 1217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_addresses_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-hours",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gross-alcohol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "julian-maldives",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "id": "retained-python",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_file=TRAIN_CSV_PATH):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.df = self.df[self.df['labels'].notnull()]\n",
    "        self.df['labels'] = self.df['labels'].apply(literal_eval)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        raw_address = self.df.iloc[idx]['sanitized_raw_address']\n",
    "        POI, street = self.df.iloc[idx]['POI/street'].split('/')\n",
    "        labels = self.df.iloc[idx]['labels']\n",
    "        return raw_address, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "id": "brief-saturday",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "id": "personalized-maryland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>id</th>\n",
       "      <th>raw_address</th>\n",
       "      <th>POI/street</th>\n",
       "      <th>sanitized_raw_address</th>\n",
       "      <th>is_clean</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4941</td>\n",
       "      <td>4941</td>\n",
       "      <td>hadi raya kre, no 29 balaraja</td>\n",
       "      <td>hadi/raya kre</td>\n",
       "      <td>hadi raya kre , no 29 balaraja</td>\n",
       "      <td>True</td>\n",
       "      <td>[PointOfInterest, Street, Street, Other, Other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>115253</td>\n",
       "      <td>115253</td>\n",
       "      <td>merak 11, no 10 cikarang utara</td>\n",
       "      <td>/merak 11</td>\n",
       "      <td>merak 11 , no 10 cikarang utara</td>\n",
       "      <td>True</td>\n",
       "      <td>[Street, Street, Other, Other, Other, Other, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>299321</td>\n",
       "      <td>299321</td>\n",
       "      <td>hotel fairmont jl asia afrika 8 gelora bung karno</td>\n",
       "      <td>bung karno/jl asia afrika</td>\n",
       "      <td>hotel fairmont jl asia afrika 8 gelora bung karno</td>\n",
       "      <td>True</td>\n",
       "      <td>[Other, Other, Street, Street, Street, Other, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>173570</td>\n",
       "      <td>173570</td>\n",
       "      <td>kar anyar d, 4 karang anyar rt 15 1 sawah besar</td>\n",
       "      <td>/kar anyar d</td>\n",
       "      <td>kar anyar d , 4 karang anyar rt 15 1 sawah besar</td>\n",
       "      <td>True</td>\n",
       "      <td>[Street, Street, Street, Other, Other, Other, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>30862</td>\n",
       "      <td>30862</td>\n",
       "      <td>roban gg. bakti 135 singkawang tengah</td>\n",
       "      <td>/gg. bakti</td>\n",
       "      <td>roban gg. bakti 135 singkawang tengah</td>\n",
       "      <td>True</td>\n",
       "      <td>[Other, Street, Street, Other, Other, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239995</th>\n",
       "      <td>239995</td>\n",
       "      <td>239995</td>\n",
       "      <td>5274</td>\n",
       "      <td>5274</td>\n",
       "      <td>cata xii,</td>\n",
       "      <td>/cata xii</td>\n",
       "      <td>cata xii ,</td>\n",
       "      <td>True</td>\n",
       "      <td>[Street, Street, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239996</th>\n",
       "      <td>239996</td>\n",
       "      <td>239996</td>\n",
       "      <td>161682</td>\n",
       "      <td>161682</td>\n",
       "      <td>nga jaya 27 1 pucang sewu gubeng</td>\n",
       "      <td>/nga jaya</td>\n",
       "      <td>nga jaya 27 1 pucang sewu gubeng</td>\n",
       "      <td>True</td>\n",
       "      <td>[Street, Street, Other, Other, Other, Other, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239997</th>\n",
       "      <td>239997</td>\n",
       "      <td>239997</td>\n",
       "      <td>28853</td>\n",
       "      <td>28853</td>\n",
       "      <td>taman ubud lest v no 21 binong curug</td>\n",
       "      <td>/taman ubud lest v</td>\n",
       "      <td>taman ubud lest v no 21 binong curug</td>\n",
       "      <td>True</td>\n",
       "      <td>[Street, Street, Street, Street, Other, Other,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239998</th>\n",
       "      <td>239998</td>\n",
       "      <td>239998</td>\n",
       "      <td>298534</td>\n",
       "      <td>298534</td>\n",
       "      <td>raya riga tanjung ganti i kelam tengah</td>\n",
       "      <td>/raya riga</td>\n",
       "      <td>raya riga tanjung ganti i kelam tengah</td>\n",
       "      <td>True</td>\n",
       "      <td>[Street, Street, Other, Other, Other, Other, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239999</th>\n",
       "      <td>239999</td>\n",
       "      <td>239999</td>\n",
       "      <td>262227</td>\n",
       "      <td>262227</td>\n",
       "      <td>gg. gad iii 48 pisangan timur rt 4 14 pulo gadung</td>\n",
       "      <td>/</td>\n",
       "      <td>gg. gad iii 48 pisangan timur rt 4 14 pulo gadung</td>\n",
       "      <td>True</td>\n",
       "      <td>[Other, Other, Other, Other, Other, Other, Oth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188882 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1      id  \\\n",
       "0                0             0            4941    4941   \n",
       "2                2             2          115253  115253   \n",
       "3                3             3          299321  299321   \n",
       "4                4             4          173570  173570   \n",
       "5                5             5           30862   30862   \n",
       "...            ...           ...             ...     ...   \n",
       "239995      239995        239995            5274    5274   \n",
       "239996      239996        239996          161682  161682   \n",
       "239997      239997        239997           28853   28853   \n",
       "239998      239998        239998          298534  298534   \n",
       "239999      239999        239999          262227  262227   \n",
       "\n",
       "                                              raw_address  \\\n",
       "0                           hadi raya kre, no 29 balaraja   \n",
       "2                          merak 11, no 10 cikarang utara   \n",
       "3       hotel fairmont jl asia afrika 8 gelora bung karno   \n",
       "4         kar anyar d, 4 karang anyar rt 15 1 sawah besar   \n",
       "5                   roban gg. bakti 135 singkawang tengah   \n",
       "...                                                   ...   \n",
       "239995                                          cata xii,   \n",
       "239996                   nga jaya 27 1 pucang sewu gubeng   \n",
       "239997               taman ubud lest v no 21 binong curug   \n",
       "239998             raya riga tanjung ganti i kelam tengah   \n",
       "239999  gg. gad iii 48 pisangan timur rt 4 14 pulo gadung   \n",
       "\n",
       "                       POI/street  \\\n",
       "0                   hadi/raya kre   \n",
       "2                       /merak 11   \n",
       "3       bung karno/jl asia afrika   \n",
       "4                    /kar anyar d   \n",
       "5                      /gg. bakti   \n",
       "...                           ...   \n",
       "239995                  /cata xii   \n",
       "239996                  /nga jaya   \n",
       "239997         /taman ubud lest v   \n",
       "239998                 /raya riga   \n",
       "239999                          /   \n",
       "\n",
       "                                    sanitized_raw_address  is_clean  \\\n",
       "0                          hadi raya kre , no 29 balaraja      True   \n",
       "2                         merak 11 , no 10 cikarang utara      True   \n",
       "3       hotel fairmont jl asia afrika 8 gelora bung karno      True   \n",
       "4        kar anyar d , 4 karang anyar rt 15 1 sawah besar      True   \n",
       "5                   roban gg. bakti 135 singkawang tengah      True   \n",
       "...                                                   ...       ...   \n",
       "239995                                         cata xii ,      True   \n",
       "239996                   nga jaya 27 1 pucang sewu gubeng      True   \n",
       "239997               taman ubud lest v no 21 binong curug      True   \n",
       "239998             raya riga tanjung ganti i kelam tengah      True   \n",
       "239999  gg. gad iii 48 pisangan timur rt 4 14 pulo gadung      True   \n",
       "\n",
       "                                                   labels  \n",
       "0       [PointOfInterest, Street, Street, Other, Other...  \n",
       "2       [Street, Street, Other, Other, Other, Other, O...  \n",
       "3       [Other, Other, Street, Street, Street, Other, ...  \n",
       "4       [Street, Street, Street, Other, Other, Other, ...  \n",
       "5            [Other, Street, Street, Other, Other, Other]  \n",
       "...                                                   ...  \n",
       "239995                            [Street, Street, Other]  \n",
       "239996  [Street, Street, Other, Other, Other, Other, O...  \n",
       "239997  [Street, Street, Street, Street, Other, Other,...  \n",
       "239998  [Street, Street, Other, Other, Other, Other, O...  \n",
       "239999  [Other, Other, Other, Other, Other, Other, Oth...  \n",
       "\n",
       "[188882 rows x 9 columns]"
      ]
     },
     "execution_count": 1220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-broadway",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "id": "italian-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_addresses = [\n",
    "    [\"50 Hello ave\", [\"Other\", \"Other\", \"Other\"]], \n",
    "    [\"SS road\", [\"Other\", \"Other\"]],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "id": "oriented-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = BPEmbVectorizer(embeddings_model=emb_model)\n",
    "tags_vectorizer = TagsConverter(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "id": "tutorial-cutting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "import pprint\n",
    "numpy.set_printoptions(threshold=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "id": "white-cinema",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = []\n",
    "target_sequence = []\n",
    "\n",
    "input_sequence.extend(vectorizer([address[0] for address in test_addresses]))\n",
    "for address in test_addresses:\n",
    "    target_tmp = [tags_vectorizer(target) for target in address[1]]\n",
    "    target_tmp.append(tags_vectorizer(\"EOS\"))\n",
    "    target_sequence.append(target_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "id": "domestic-metro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([[array([-0.032396, -0.051103,  0.449281, ...,  0.354258, -0.630191,\n",
       "            0.640046], dtype=float32),\n",
       "    array([0., 0., 0., ..., 0., 0., 0.])],\n",
       "   [array([ 0.119792, -0.087593, -0.366256, ..., -0.126352,  0.036049,\n",
       "            0.363969], dtype=float32),\n",
       "    array([ 0.302875, -0.092815, -0.317463, ...,  0.52216 , -0.115126,\n",
       "            0.237173], dtype=float32)],\n",
       "   [array([ 0.271623, -0.318372,  0.468792, ...,  0.548052,  0.273256,\n",
       "           -0.513469], dtype=float32),\n",
       "    array([0., 0., 0., ..., 0., 0., 0.])]],\n",
       "  [1, 2, 1]),\n",
       " ([[array([-0.126823,  0.425704,  0.154299, ...,  0.366716,  0.07786 ,\n",
       "            0.562716], dtype=float32),\n",
       "    array([0., 0., 0., ..., 0., 0., 0.])],\n",
       "   [array([-0.147449,  0.12949 , -0.107977, ...,  0.101064,  0.264715,\n",
       "            0.098076], dtype=float32),\n",
       "    array([0., 0., 0., ..., 0., 0., 0.])]],\n",
       "  [1, 1])]"
      ]
     },
     "execution_count": 1225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "id": "recreational-offering",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 2, 2, 3], [2, 2, 3]]"
      ]
     },
     "execution_count": 1226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-apartment",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1227,
   "id": "intended-sentence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_bpemb_sequence_to_tensor(batch):\n",
    "    \"\"\"\n",
    "    Sort and convert a BPEmb sequence into a tensor with target element\n",
    "    \"\"\"\n",
    "    sorted_batch = sorted(batch, key=lambda x: len(x[0][1]), reverse=True)\n",
    "    return zip(*[(torch.tensor(vectors), word_decomposition_len, torch.tensor(target_vectors), len(vectors))\n",
    "                 for (vectors, word_decomposition_len), target_vectors in sorted_batch])\n",
    "\n",
    "def bpemb_data_padding_with_target(batch: List[Tuple]) -> Tuple:\n",
    "    \"\"\"\n",
    "    Function that add padding to the sequences and to the decomposition lengths so all can have the same length as\n",
    "    the longest one.\n",
    "    Args:\n",
    "        batch (list[tuple]): The list of vectorize tupled batch data where the first element is the address embeddings\n",
    "            and the second is the word decomposition lengths.\n",
    "    Returns:\n",
    "        A tuple ((``x``, ``y`` , ``z``), ``w``). The element ``x`` is a tensor of padded word vectors,\n",
    "        ``y`` is the padded decomposition lengths, ``z`` is the original lengths of the sequences before padding, and\n",
    "        ``w`` is a tensor of padded target idx.\n",
    "    \"\"\"\n",
    "\n",
    "    sequences_vectors, decomp_len, target_vectors, lengths = _convert_bpemb_sequence_to_tensor(batch)\n",
    "\n",
    "    lengths = torch.tensor(lengths)\n",
    "\n",
    "    padded_sequences_vectors = pad_sequence(sequences_vectors, batch_first=True, padding_value=padding_value)\n",
    "    padded_target_vectors = pad_sequence(target_vectors, batch_first=True, padding_value=padding_value)\n",
    "\n",
    "    # pad decomposition length\n",
    "    max_sequence_length = lengths.max().item()\n",
    "    for decomposition_length in decomp_len:\n",
    "        if len(decomposition_length) < max_sequence_length:\n",
    "            decomposition_length.extend([1] * (max_sequence_length - len(decomposition_length)))\n",
    "\n",
    "    return (padded_sequences_vectors, list(decomp_len), lengths), padded_target_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1228,
   "id": "active-marking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "id": "concerned-reflection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn_train(batch_pairs):\n",
    "    input_sequence = []\n",
    "    target_sequence = []\n",
    "\n",
    "    input_sequence.extend(vectorizer([address[0] for address in batch_pairs]))\n",
    "    for address in batch_pairs:\n",
    "        target_tmp = [tags_vectorizer(target) for target in address[1]]\n",
    "        target_tmp.append(tags_vectorizer(\"EOS\"))\n",
    "        target_sequence.append(target_tmp)\n",
    "        \n",
    "    raw = [address[0] for address in batch_pairs]\n",
    "    return raw, zip(input_sequence, target_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1234,
   "id": "atmospheric-teaching",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=2, collate_fn=collate_fn_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "id": "brave-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2SeqModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1253,
   "id": "recent-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "english-timber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19e2de5661e4769951e6e95f3103593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "danau singk raya 14-15 abadijaya sukmajaya [('danau', 'Street', 'Other'), ('singk', 'Other', 'Street'), ('raya', 'Other', 'Street'), ('14-15', 'Other', 'Street'), ('abadijaya', 'Other', 'Street'), ('sukmajaya', 'Other', 'Other')]\n",
      "bunga mata xv , jatirahayu kel. pondok melati [('bunga', 'Street', 'Street'), ('mata', 'Other', 'Street'), ('xv', 'Other', 'Street'), (',', 'Other', 'Other'), ('jatirahayu', 'Other', 'Other'), ('kel.', 'Other', 'Other'), ('pondok', 'Other', 'Other'), ('melati', 'Other', 'Other')]\n",
      "aricell 4 , kh abu bakar , [('aricell', 'Street', 'Other'), ('4', 'Other', 'Other'), (',', 'Other', 'Other'), ('kh', 'Other', 'Street'), ('abu', 'Other', 'Street'), ('bakar', 'Other', 'Other'), (',', 'Other', 'Other')]\n",
      "y. teluk gong 24 rt 10 10 pejagalan penjaringan [('y.', 'Street', 'Street'), ('teluk', 'Street', 'Street'), ('gong', 'Other', 'Street'), ('24', 'Other', 'Other'), ('rt', 'Other', 'Other'), ('10', 'Other', 'Other'), ('10', 'Other', 'Other'), ('pejagalan', 'Other', 'Other'), ('penjaringan', 'Other', 'Other')]\n",
      "universitas internasional batam , jl. gajah mada , baloi sei ladi batam , 29442 [('universitas', 'Street', 'Other'), ('internasional', 'Street', 'Other'), ('batam', 'Other', 'Other'), (',', 'Other', 'Other'), ('jl.', 'Other', 'Street'), ('gajah', 'Other', 'Street'), ('mada', 'Other', 'Street'), (',', 'Other', 'Other'), ('baloi', 'Other', 'Other'), ('sei', 'Other', 'PointOfInterest'), ('ladi', 'Other', 'PointOfInterest'), ('batam', 'Other', 'Other'), (',', 'EOS', 'Other'), ('29442', 'EOS', 'Other')]\n",
      "pasar palmerah [('pasar', 'Street', 'PointOfInterest'), ('palmerah', 'Street', 'PointOfInterest')]\n",
      "al muba raya 35 joglo rw 2 kembangan [('al', 'Street', 'Street'), ('muba', 'Street', 'Street'), ('raya', 'Other', 'Street'), ('35', 'Other', 'Other'), ('joglo', 'Other', 'Other'), ('rw', 'Other', 'Other'), ('2', 'Other', 'Other'), ('kembangan', 'Other', 'Other')]\n",
      "serdang kel. serd baru 12 no 32c rw 5 kemayoran [('serdang', 'Street', 'Other'), ('kel.', 'Other', 'Other'), ('serd', 'Other', 'Street'), ('baru', 'Other', 'Street'), ('12', 'Other', 'Street'), ('no', 'Other', 'Other'), ('32c', 'Other', 'Other'), ('rw', 'Other', 'Other'), ('5', 'Other', 'Other'), ('kemayoran', 'Other', 'Other')]\n",
      "bla , no 31 gm pet shop danau buyan , denpasar utara [('bla', 'Street', 'Street'), (',', 'Street', 'Other'), ('no', 'Other', 'Other'), ('31', 'Other', 'Other'), ('gm', 'Other', 'PointOfInterest'), ('pet', 'Other', 'PointOfInterest'), ('shop', 'Other', 'PointOfInterest'), ('danau', 'Other', 'PointOfInterest'), ('buyan', 'Other', 'PointOfInterest'), (',', 'Other', 'Other'), ('denpasar', 'Other', 'Other'), ('utara', 'Other', 'Other')]\n",
      "pt. mitraperkasa jayame sentul jaya balaraja [('pt.', 'Street', 'Other'), ('mitraperkasa', 'Other', 'Other'), ('jayame', 'Other', 'Street'), ('sentul', 'Other', 'Street'), ('jaya', 'Other', 'Other'), ('balaraja', 'Other', 'Other')]\n",
      "popoh raya jimb kulon 69 [('popoh', 'Street', 'Street'), ('raya', 'Other', 'Street'), ('jimb', 'Other', 'Other'), ('kulon', 'Other', 'Other'), ('69', 'Other', 'Other')]\n",
      "pulau suma 34 tualang padang hulu [('pulau', 'Street', 'Street'), ('suma', 'Other', 'Street'), ('34', 'Other', 'Other'), ('tualang', 'Other', 'Other'), ('padang', 'Other', 'Other'), ('hulu', 'Other', 'Other')]\n",
      "kota gapura jl pelangi ii 52 kotabumi [('kota', 'Other', 'Street'), ('gapura', 'Other', 'Street'), ('jl', 'Other', 'Street'), ('pelangi', 'Other', 'Other'), ('ii', 'Other', 'Other'), ('52', 'Other', 'Other'), ('kotabumi', 'Other', 'Other')]\n",
      "erha mebel tambak wedi jaya i , [('erha', 'Other', 'Street'), ('mebel', 'Other', 'Street'), ('tambak', 'Other', 'Street'), ('wedi', 'Other', 'Street'), ('jaya', 'Other', 'Street'), ('i', 'Other', 'Street'), (',', 'Other', 'Other')]\n",
      "cemp i , bojong kulur gunung putri [('cemp', 'Street', 'PointOfInterest'), ('i', 'Street', 'PointOfInterest'), (',', 'Street', 'PointOfInterest'), ('bojong', 'Street', 'Other'), ('kulur', 'Other', 'Street'), ('gunung', 'Other', 'Street'), ('putri', 'Other', 'Other')]\n",
      "indomaret , nganjuk [('indomaret', 'Street', 'PointOfInterest'), (',', 'Other', 'Other'), ('nganjuk', 'Other', 'Other')]\n",
      "pid 158 rt 7 4 wijaya kusuma grogol petamburan [('pid', 'Street', 'Other'), ('158', 'Street', 'Other'), ('rt', 'Other', 'Other'), ('7', 'Other', 'Other'), ('4', 'Other', 'Other'), ('wijaya', 'Other', 'Other'), ('kusuma', 'Other', 'Other'), ('grogol', 'Other', 'Other'), ('petamburan', 'Other', 'Other')]\n",
      "kemi gg. pel , 10 pondok cabe udik rt 3 3 [('kemi', 'PointOfInterest', 'Street'), ('gg.', 'PointOfInterest', 'Street'), ('pel', 'PointOfInterest', 'Street'), (',', 'PointOfInterest', 'Other'), ('10', 'Other', 'Other'), ('pondok', 'Other', 'Other'), ('cabe', 'Other', 'Other'), ('udik', 'Other', 'Other'), ('rt', 'Other', 'Other'), ('3', 'Other', 'Other'), ('3', 'Other', 'Other')]\n",
      "pondok kacang timur maha vi 37 [('pondok', 'Other', 'Other'), ('kacang', 'Other', 'Other'), ('timur', 'Other', 'Other'), ('maha', 'Other', 'Other'), ('vi', 'Other', 'Street'), ('37', 'Other', 'Other')]\n",
      "sidol xvii , pedurungan [('sidol', 'Other', 'Street'), ('xvii', 'Other', 'Street'), (',', 'Other', 'Other'), ('pedurungan', 'Other', 'Other')]\n",
      "sudirman plaza ,gedung plaza marein lt7 jl jendral sudirman kav 76-78 jakarta 12910 [('sudirman', 'Other', 'Other'), ('plaza', 'Other', 'Other'), (',gedung', 'Other', 'Other'), ('plaza', 'Other', 'PointOfInterest'), ('marein', 'Other', 'PointOfInterest'), ('lt7', 'Other', 'Other'), ('jl', 'Other', 'Street'), ('jendral', 'Other', 'Street'), ('sudirman', 'Other', 'Street'), ('kav', 'Other', 'Other'), ('76-78', 'Other', 'Other'), ('jakarta', 'Other', 'Other'), ('12910', 'EOS', 'Other')]\n",
      "mera gun 14 tanjung gading tanjung karang timur [('mera', 'Other', 'Street'), ('gun', 'Street', 'Street'), ('14', 'Other', 'Other'), ('tanjung', 'Other', 'Other'), ('gading', 'Other', 'Other'), ('tanjung', 'Other', 'Other'), ('karang', 'Other', 'Other'), ('timur', 'EOS', 'Other')]\n",
      "boule pan m masale panakkukang [('boule', 'Street', 'Other'), ('pan', 'Street', 'Other'), ('m', 'Street', 'Street'), ('masale', 'Other', 'Street'), ('panakkukang', 'Other', 'Street')]\n",
      "obor iii balik alam kel. mandau [('obor', 'Street', 'Street'), ('iii', 'Street', 'Street'), ('balik', 'Other', 'Other'), ('alam', 'Other', 'Other'), ('kel.', 'Other', 'Other'), ('mandau', 'Other', 'Other')]\n",
      "jan raya 95 jatingaleh 1 candisari [('jan', 'Street', 'Street'), ('raya', 'Other', 'Street'), ('95', 'Other', 'Other'), ('jatingaleh', 'Other', 'Other'), ('1', 'Other', 'Other'), ('candisari', 'Other', 'Other')]\n",
      "alamat: the anmon resort , jln raja haji km 01 no 88 kawasan pariwisata , teluk sebong lagoi [('alamat:', 'Other', 'Other'), ('the', 'Other', 'Other'), ('anmon', 'Other', 'Other'), ('resort', 'Other', 'Other'), (',', 'Other', 'Other'), ('jln', 'Other', 'Street'), ('raja', 'Other', 'Street'), ('haji', 'Other', 'Street'), ('km', 'Other', 'Other'), ('01', 'Other', 'Other'), ('no', 'Other', 'Other'), ('88', 'Other', 'Other'), ('kawasan', 'Other', 'PointOfInterest'), ('pariwisata', 'Other', 'PointOfInterest'), (',', 'Other', 'Other'), ('teluk', 'Other', 'Other'), ('sebong', 'EOS', 'Other'), ('lagoi', 'EOS', 'Other')]\n",
      "stokis luxor , grama taman wana sari cibitung [('stokis', 'Street', 'Other'), ('luxor', 'Street', 'Street'), (',', 'Other', 'Street'), ('grama', 'Other', 'Street'), ('taman', 'Other', 'Other'), ('wana', 'Other', 'Other'), ('sari', 'Other', 'Other'), ('cibitung', 'Other', 'Other')]\n",
      "sei pad 76 merdeka medan baru [('sei', 'PointOfInterest', 'Street'), ('pad', 'Street', 'Street'), ('76', 'Other', 'Other'), ('merdeka', 'Other', 'Other'), ('medan', 'Other', 'Other'), ('baru', 'Other', 'Other')]\n",
      "cv. mario perkasa , [('cv.', 'Street', 'PointOfInterest'), ('mario', 'Other', 'PointOfInterest'), ('perkasa', 'Other', 'PointOfInterest'), (',', 'Other', 'Other')]\n",
      "ivana baby , niaga melayu [('ivana', 'Other', 'Street'), ('baby', 'Other', 'Street'), (',', 'Other', 'Street'), ('niaga', 'Other', 'Other'), ('melayu', 'Other', 'Other')]\n",
      "bukit tin , no 51 rambung timur binjai selatan [('bukit', 'Other', 'Street'), ('tin', 'PointOfInterest', 'Street'), (',', 'PointOfInterest', 'Other'), ('no', 'Other', 'Other'), ('51', 'Other', 'Other'), ('rambung', 'Other', 'Other'), ('timur', 'Other', 'Other'), ('binjai', 'Other', 'Other'), ('selatan', 'EOS', 'Other')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "btn cendana carangki [('btn', 'Street', 'Street'), ('cendana', 'Street', 'Street'), ('carangki', 'Other', 'Other')]\n",
      "pasu menteng menteng [('pasu', 'Street', 'Other'), ('menteng', 'Other', 'Other'), ('menteng', 'Other', 'Other')]\n",
      "kembangarum borob timur i 48 9 50183 semarang barat [('kembangarum', 'Street', 'Other'), ('borob', 'Street', 'Street'), ('timur', 'Street', 'Street'), ('i', 'Street', 'Street'), ('48', 'Street', 'Other'), ('9', 'Other', 'Other'), ('50183', 'Other', 'Other'), ('semarang', 'Other', 'Other'), ('barat', 'Other', 'Other')]\n",
      "beri 8 kepunduhan kramat [('beri', 'Street', 'Street'), ('8', 'Other', 'Other'), ('kepunduhan', 'Other', 'Other'), ('kramat', 'Other', 'Other')]\n",
      "sabi no 31 kotabaru gondokusuman [('sabi', 'Street', 'Street'), ('no', 'Other', 'Other'), ('31', 'Other', 'Other'), ('kotabaru', 'Other', 'Other'), ('gondokusuman', 'Other', 'Other')]\n",
      "20 ilir d ii jl. amp 18 1978 kemuning [('20', 'Street', 'Other'), ('ilir', 'Street', 'Other'), ('d', 'Street', 'Other'), ('ii', 'Other', 'Other'), ('jl.', 'Other', 'Street'), ('amp', 'Other', 'Street'), ('18', 'Other', 'Other'), ('1978', 'Other', 'Other'), ('kemuning', 'Other', 'Other')]\n",
      "ngunut demuk lk. ii ngunut [('ngunut', 'Street', 'Other'), ('demuk', 'Street', 'Street'), ('lk.', 'Other', 'Other'), ('ii', 'Other', 'Other'), ('ngunut', 'Other', 'Other')]\n",
      "bonto makkio jl. tid 3 blo 45 rappocini [('bonto', 'Other', 'Other'), ('makkio', 'Other', 'Other'), ('jl.', 'Other', 'Street'), ('tid', 'Other', 'Street'), ('3', 'Other', 'Street'), ('blo', 'Other', 'Street'), ('45', 'Other', 'Other'), ('rappocini', 'Other', 'Other')]\n",
      "tanah baru i 81 rt 7 11 grogol utara kebayoran lama [('tanah', 'Other', 'Street'), ('baru', 'Other', 'Street'), ('i', 'Other', 'Street'), ('81', 'Other', 'Other'), ('rt', 'Other', 'Other'), ('7', 'Other', 'Other'), ('11', 'Other', 'Other'), ('grogol', 'Other', 'Other'), ('utara', 'Other', 'Other'), ('kebayoran', 'Other', 'Other'), ('lama', 'Other', 'Other')]\n",
      "mampang prap 17 , [('mampang', 'Street', 'Other'), ('prap', 'Street', 'Other'), ('17', 'Other', 'Other'), (',', 'Other', 'Other')]\n",
      "kij sela vii birobuli selatan palu selatan [('kij', 'Street', 'Street'), ('sela', 'Street', 'Street'), ('vii', 'Street', 'Street'), ('birobuli', 'Other', 'Other'), ('selatan', 'Other', 'Other'), ('palu', 'Other', 'Other'), ('selatan', 'Other', 'Other')]\n",
      "cipa 125 kujangsari bandung kidul [('cipa', 'Street', 'Street'), ('125', 'Street', 'Other'), ('kujangsari', 'Other', 'Other'), ('bandung', 'Other', 'Other'), ('kidul', 'Other', 'Other')]\n",
      "tirtha ria. pt , [('tirtha', 'Other', 'PointOfInterest'), ('ria.', 'Other', 'PointOfInterest'), ('pt', 'Other', 'PointOfInterest'), (',', 'Other', 'PointOfInterest')]\n",
      "h kha 97-99 pondok kacang timur pondok aren [('h', 'Street', 'Street'), ('kha', 'Street', 'Street'), ('97-99', 'Other', 'Other'), ('pondok', 'Other', 'Other'), ('kacang', 'Other', 'Other'), ('timur', 'Other', 'Other'), ('pondok', 'Other', 'Other'), ('aren', 'Other', 'Other')]\n",
      "nasi goreng 67 dan moo nyusu murni pan cibiru wetan cileunyi [('nasi', 'Other', 'PointOfInterest'), ('goreng', 'Street', 'PointOfInterest'), ('67', 'Street', 'PointOfInterest'), ('dan', 'Street', 'PointOfInterest'), ('moo', 'Other', 'PointOfInterest'), ('nyusu', 'Other', 'PointOfInterest'), ('murni', 'Other', 'PointOfInterest'), ('pan', 'Other', 'Street'), ('cibiru', 'Other', 'Other'), ('wetan', 'Other', 'Other'), ('cileunyi', 'Other', 'Other')]\n",
      "tosca motor , pang tuba angke wijaya kesuma grogol petamburan [('tosca', 'Other', 'PointOfInterest'), ('motor', 'PointOfInterest', 'PointOfInterest'), (',', 'PointOfInterest', 'Other'), ('pang', 'Other', 'Street'), ('tuba', 'Other', 'Street'), ('angke', 'Other', 'Street'), ('wijaya', 'Other', 'Other'), ('kesuma', 'Other', 'Other'), ('grogol', 'Other', 'Other'), ('petamburan', 'Other', 'Other')]\n",
      "tam lan iv no 10 6 tambak langon asemrowo [('tam', 'Street', 'Street'), ('lan', 'Street', 'Street'), ('iv', 'Street', 'Street'), ('no', 'Street', 'Other'), ('10', 'Other', 'Other'), ('6', 'Other', 'Other'), ('tambak', 'Other', 'Other'), ('langon', 'Other', 'Other'), ('asemrowo', 'Other', 'Other')]\n",
      "koleksi bunda , cisauk [('koleksi', 'Street', 'Street'), ('bunda', 'Other', 'Street'), (',', 'Other', 'Other'), ('cisauk', 'Other', 'Other')]\n",
      "b-blouse , mayor oking , cibinong [('b-blouse', 'Street', 'PointOfInterest'), (',', 'Street', 'PointOfInterest'), ('mayor', 'Street', 'Other'), ('oking', 'Other', 'Street'), (',', 'Other', 'Street'), ('cibinong', 'Other', 'Street')]\n",
      "wono pab kulit , wonocolo [('wono', 'Street', 'PointOfInterest'), ('pab', 'Street', 'PointOfInterest'), ('kulit', 'Other', 'PointOfInterest'), (',', 'Other', 'Other'), ('wonocolo', 'Other', 'Other')]\n",
      "kli hipnoterapi jaka , rw 4 pancoran [('kli', 'Other', 'Street'), ('hipnoterapi', 'Street', 'Street'), ('jaka', 'Street', 'Other'), (',', 'Other', 'Other'), ('rw', 'Other', 'Other'), ('4', 'Other', 'Other'), ('pancoran', 'Other', 'Other')]\n",
      "sinoman tem no 255 sidorejo [('sinoman', 'Other', 'PointOfInterest'), ('tem', 'PointOfInterest', 'PointOfInterest'), ('no', 'PointOfInterest', 'PointOfInterest'), ('255', 'Street', 'PointOfInterest'), ('sidorejo', 'Other', 'Street')]\n",
      "karangsari salak 29 sukorejo [('karangsari', 'Other', 'Other'), ('salak', 'Street', 'Other'), ('29', 'Other', 'Street'), ('sukorejo', 'Other', 'Street')]\n",
      "jl. haji ilyas rempoa ciputat timur [('jl.', 'Street', 'Street'), ('haji', 'Street', 'Street'), ('ilyas', 'Other', 'Street'), ('rempoa', 'Other', 'Other'), ('ciputat', 'Other', 'Other'), ('timur', 'Other', 'Other')]\n",
      "angg rege gumpang kartasura [('angg', 'Other', 'PointOfInterest'), ('rege', 'Street', 'PointOfInterest'), ('gumpang', 'Street', 'PointOfInterest'), ('kartasura', 'Other', 'PointOfInterest')]\n",
      "wr. supra cimuning mustika jaya [('wr.', 'Street', 'Other'), ('supra', 'Street', 'Street'), ('cimuning', 'Other', 'Street'), ('mustika', 'Other', 'Other'), ('jaya', 'Other', 'Other')]\n",
      "usman sadar gang 4 , kemuteran kel. [('usman', 'Street', 'Street'), ('sadar', 'Street', 'Street'), ('gang', 'Other', 'Street'), ('4', 'Other', 'Street'), (',', 'Other', 'Other'), ('kemuteran', 'Other', 'Other'), ('kel.', 'Other', 'Other')]\n",
      "kerobokan gg. way 29 , kuta utara [('kerobokan', 'Street', 'Street'), ('gg.', 'Street', 'Street'), ('way', 'Street', 'Street'), ('29', 'Other', 'Street'), (',', 'Other', 'Other'), ('kuta', 'Other', 'Other'), ('utara', 'Other', 'Other')]\n",
      "mrisi , tirtonirmolo kel. [('mrisi', 'Street', 'Street'), (',', 'Street', 'Street'), ('tirtonirmolo', 'Other', 'Other'), ('kel.', 'Other', 'Other')]\n",
      "mawar no 8 pedurenan rt 2 3 karang tengah [('mawar', 'Street', 'Street'), ('no', 'Street', 'Other'), ('8', 'Other', 'Other'), ('pedurenan', 'Other', 'Other'), ('rt', 'Other', 'Other'), ('2', 'Other', 'Other'), ('3', 'Other', 'Other'), ('karang', 'Other', 'Other'), ('tengah', 'Other', 'Other')]\n",
      "muf raya suko , pekarungan sukodono [('muf', 'Street', 'Other'), ('raya', 'Street', 'Other'), ('suko', 'Other', 'Other'), (',', 'Other', 'Other'), ('pekarungan', 'Other', 'Other'), ('sukodono', 'Other', 'Other')]\n",
      "wono send iv , no 17 rw 5 50242 [('wono', 'Other', 'Other'), ('send', 'Street', 'Other'), ('iv', 'Street', 'Other'), (',', 'Street', 'Street'), ('no', 'Other', 'Street'), ('17', 'Other', 'Other'), ('rw', 'Other', 'Other'), ('5', 'Other', 'Other'), ('50242', 'Other', 'Other')]\n",
      "pang sudi 26 sukodadi sukodadi [('pang', 'Street', 'Street'), ('sudi', 'Street', 'Street'), ('26', 'Other', 'Other'), ('sukodadi', 'Other', 'Other'), ('sukodadi', 'Other', 'Other')]\n",
      "mek ii no 54 pemogan denpasar selatan [('mek', 'Street', 'Street'), ('ii', 'Street', 'Street'), ('no', 'Other', 'Other'), ('54', 'Other', 'Other'), ('pemogan', 'Other', 'Other'), ('denpasar', 'Other', 'Other'), ('selatan', 'Other', 'Other')]\n",
      "prat 8 7 larangan [('prat', 'PointOfInterest', 'Street'), ('8', 'Street', 'Street'), ('7', 'Other', 'Other'), ('larangan', 'Other', 'PointOfInterest')]\n",
      "raya pati - kudus , 87 [('raya', 'Street', 'Street'), ('pati', 'Other', 'Street'), ('-', 'Other', 'Street'), ('kudus', 'Other', 'Street'), (',', 'Other', 'Other'), ('87', 'Other', 'Other')]\n",
      "minak koncar , 22 citrodiwangsan [('minak', 'Street', 'Street'), ('koncar', 'Street', 'Street'), (',', 'Other', 'Other'), ('22', 'Other', 'Other'), ('citrodiwangsan', 'Other', 'Other')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sri rejo kel. [('sri', 'Other', 'Other'), ('rejo', 'Other', 'Other'), ('kel.', 'Other', 'Other')]\n",
      "pasar ulekan lantai 2 no.16 (thirafi advertising) [('pasar', 'Other', 'Other'), ('ulekan', 'Other', 'Other'), ('lantai', 'Other', 'Other'), ('2', 'Other', 'Other'), ('no.16', 'Other', 'Other'), ('(thirafi', 'Other', 'Other'), ('advertising)', 'Other', 'Other')]\n",
      "dondang sut , rt 5 75264 muara jawa [('dondang', 'Other', 'Street'), ('sut', 'Other', 'Street'), (',', 'Other', 'Street'), ('rt', 'Other', 'Street'), ('5', 'Other', 'Other'), ('75264', 'Other', 'Other'), ('muara', 'Other', 'Other'), ('jawa', 'Other', 'Other')]\n",
      "aqef , mel , 14 kepanjen kidul [('aqef', 'Other', 'Street'), (',', 'Other', 'Street'), ('mel', 'Other', 'Street'), (',', 'Other', 'Street'), ('14', 'Other', 'Street'), ('kepanjen', 'Other', 'Other'), ('kidul', 'Other', 'Other')]\n",
      "purworejo brawi , rt 3 rw 4 sanan kulon [('purworejo', 'Other', 'Street'), ('brawi', 'Other', 'Other'), (',', 'Other', 'Other'), ('rt', 'Other', 'Other'), ('3', 'Other', 'PointOfInterest'), ('rw', 'Other', 'PointOfInterest'), ('4', 'Other', 'Other'), ('sanan', 'Other', 'Other'), ('kulon', 'Other', 'Other')]\n",
      "gg. sar i 8 pulo gebang cakung [('gg.', 'PointOfInterest', 'Other'), ('sar', 'PointOfInterest', 'Other'), ('i', 'PointOfInterest', 'Other'), ('8', 'PointOfInterest', 'Other'), ('pulo', 'PointOfInterest', 'Other'), ('gebang', 'PointOfInterest', 'Other'), ('cakung', 'PointOfInterest', 'Other')]\n",
      "usaha baru ibu 2 , [('usaha', 'Street', 'PointOfInterest'), ('baru', 'Street', 'PointOfInterest'), ('ibu', 'Other', 'PointOfInterest'), ('2', 'Other', 'PointOfInterest'), (',', 'Other', 'Other')]\n",
      "tanah sareal jend a. yani ii 63 4 tanah sereal [('tanah', 'Other', 'Other'), ('sareal', 'Other', 'Other'), ('jend', 'Other', 'Other'), ('a.', 'Other', 'Other'), ('yani', 'Other', 'Other'), ('ii', 'Other', 'Other'), ('63', 'Other', 'Other'), ('4', 'Other', 'Street'), ('tanah', 'Other', 'Street'), ('sereal', 'Other', 'Street')]\n",
      "halte lapangan hockey surabaya airlangga [('halte', 'PointOfInterest', 'Other'), ('lapangan', 'PointOfInterest', 'Other'), ('hockey', 'PointOfInterest', 'Other'), ('surabaya', 'Other', 'Other'), ('airlangga', 'Other', 'Other')]\n",
      "gebang putih geb kidul no 48-a rt 2 2 [('gebang', 'Other', 'Other'), ('putih', 'Street', 'Other'), ('geb', 'Street', 'Other'), ('kidul', 'Other', 'Other'), ('no', 'Other', 'Other'), ('48-a', 'Other', 'Other'), ('rt', 'Other', 'Other'), ('2', 'Other', 'Other'), ('2', 'Other', 'Other')]\n",
      "haji soleh no 1f rw 2 sukabumi selatan kel. [('haji', 'Street', 'Street'), ('soleh', 'Street', 'Street'), ('no', 'Street', 'Other'), ('1f', 'Other', 'Other'), ('rw', 'Other', 'Other'), ('2', 'Other', 'Other'), ('sukabumi', 'Other', 'Other'), ('selatan', 'Other', 'Other'), ('kel.', 'Other', 'Other')]\n",
      "belly no 1 9 cijantung pasar rebo [('belly', 'Street', 'Street'), ('no', 'Street', 'Other'), ('1', 'Other', 'Other'), ('9', 'Other', 'Other'), ('cijantung', 'Other', 'Other'), ('pasar', 'Other', 'Other'), ('rebo', 'Other', 'Other')]\n",
      "bintara jaya bint jaya per no 167 rt 6 rw 11 17136 bekasi barat [('bintara', 'Other', 'Other'), ('jaya', 'Street', 'Other'), ('bint', 'Street', 'Street'), ('jaya', 'Street', 'Street'), ('per', 'Street', 'Street'), ('no', 'Other', 'Other'), ('167', 'Other', 'Other'), ('rt', 'Other', 'Other'), ('6', 'Other', 'Other'), ('rw', 'Other', 'Other'), ('11', 'Other', 'Other'), ('17136', 'Other', 'Other'), ('bekasi', 'Other', 'Other'), ('barat', 'Other', 'Other')]\n",
      "pocanan ra kart 1 kediri kota [('pocanan', 'Street', 'Other'), ('ra', 'Street', 'Street'), ('kart', 'Other', 'Street'), ('1', 'Other', 'Other'), ('kediri', 'Other', 'Other'), ('kota', 'Other', 'Other')]\n",
      "polsek linge , kute robel linge [('polsek', 'Street', 'Street'), ('linge', 'Street', 'Street'), (',', 'Street', 'Street'), ('kute', 'Other', 'Street'), ('robel', 'Other', 'Street'), ('linge', 'Other', 'Other')]\n",
      "dr. setia budi , no 84c 15153 [('dr.', 'PointOfInterest', 'Street'), ('setia', 'PointOfInterest', 'Street'), ('budi', 'PointOfInterest', 'Street'), (',', 'Street', 'Other'), ('no', 'Other', 'Other'), ('84c', 'Other', 'Other'), ('15153', 'Other', 'Other')]\n",
      "bant utara i , 12 pandean lamper rw 5 [('bant', 'PointOfInterest', 'PointOfInterest'), ('utara', 'PointOfInterest', 'PointOfInterest'), ('i', 'PointOfInterest', 'PointOfInterest'), (',', 'PointOfInterest', 'PointOfInterest'), ('12', 'PointOfInterest', 'PointOfInterest'), ('pandean', 'Other', 'Other'), ('lamper', 'Other', 'Street'), ('rw', 'Other', 'Street'), ('5', 'Other', 'Street')]\n",
      "sumbang gg. mertoy i 35 [('sumbang', 'Street', 'Street'), ('gg.', 'Street', 'Other'), ('mertoy', 'Other', 'Other'), ('i', 'Other', 'Other'), ('35', 'Other', 'Other')]\n",
      "butung kal 43 90165 wajo [('butung', 'Other', 'PointOfInterest'), ('kal', 'Other', 'PointOfInterest'), ('43', 'Other', 'Other'), ('90165', 'Other', 'Street'), ('wajo', 'Other', 'Street')]\n",
      "buana impian 2 blok dream c no 12 b kec batu aji kota batam , kepulauan riau , 29438 [('buana', 'Other', 'PointOfInterest'), ('impian', 'Other', 'PointOfInterest'), ('2', 'Other', 'PointOfInterest'), ('blok', 'Other', 'Other'), ('dream', 'Other', 'Other'), ('c', 'Other', 'Other'), ('no', 'Other', 'Other'), ('12', 'Other', 'Other'), ('b', 'Other', 'Other'), ('kec', 'Other', 'Other'), ('batu', 'Other', 'Other'), ('aji', 'Other', 'Other'), ('kota', 'Other', 'Other'), ('batam', 'Other', 'Other'), (',', 'Other', 'Other'), ('kepulauan', 'Other', 'Other'), ('riau', 'Other', 'Other'), (',', 'Other', 'Other'), ('29438', 'Other', 'Other')]\n",
      "baso karawang 27 jatiw 2 antapani tengah antapani (cicadas) [('baso', 'Other', 'Other'), ('karawang', 'Other', 'Other'), ('27', 'Other', 'Other'), ('jatiw', 'Other', 'Other'), ('2', 'Other', 'Other'), ('antapani', 'Other', 'Other'), ('tengah', 'Other', 'Other'), ('antapani', 'Other', 'Other'), ('(cicadas)', 'Other', 'Other')]\n",
      "perigi kel. mas as saa , 10 [('perigi', 'Other', 'Other'), ('kel.', 'Other', 'Other'), ('mas', 'Street', 'Street'), ('as', 'Street', 'Street'), ('saa', 'Other', 'Street'), (',', 'Other', 'Other'), ('10', 'Other', 'Other')]\n",
      "mush , ciracas [('mush', 'Street', 'Other'), (',', 'Street', 'Other'), ('ciracas', 'Other', 'Other')]\n",
      "kes 3 tamalanrea [('kes', 'PointOfInterest', 'Other'), ('3', 'Other', 'Other'), ('tamalanrea', 'Other', 'Street')]\n",
      "sunter agung danau sun utara 6 rt 8 15 14350 tanjung priok [('sunter', 'Other', 'Other'), ('agung', 'Other', 'Other'), ('danau', 'Street', 'Street'), ('sun', 'Other', 'Street'), ('utara', 'Other', 'Street'), ('6', 'Other', 'Other'), ('rt', 'Other', 'Other'), ('8', 'Other', 'Other'), ('15', 'Other', 'Other'), ('14350', 'Other', 'Other'), ('tanjung', 'Other', 'Other'), ('priok', 'Other', 'Other')]\n",
      "ciw tanah sewa cibogor bogor tengah - kota [('ciw', 'Other', 'Street'), ('tanah', 'PointOfInterest', 'Street'), ('sewa', 'Other', 'Street'), ('cibogor', 'Other', 'Other'), ('bogor', 'Other', 'Other'), ('tengah', 'Other', 'Other'), ('-', 'Other', 'Other'), ('kota', 'Other', 'Other')]\n",
      "kaliu barat i , 91 rawon kaliurang , klojen [('kaliu', 'Other', 'Street'), ('barat', 'Other', 'Street'), ('i', 'Other', 'Street'), (',', 'Other', 'Street'), ('91', 'Other', 'Other'), ('rawon', 'Other', 'PointOfInterest'), ('kaliurang', 'Other', 'PointOfInterest'), (',', 'Other', 'PointOfInterest'), ('klojen', 'Other', 'Other')]\n",
      "bandar lor gg. hima 1 35 64114 mojoroto [('bandar', 'Other', 'Other'), ('lor', 'Street', 'Other'), ('gg.', 'Street', 'Street'), ('hima', 'Other', 'Street'), ('1', 'Other', 'Street'), ('35', 'Other', 'Other'), ('64114', 'Other', 'Other'), ('mojoroto', 'Other', 'Other')]\n",
      "kemu no 15 karawang barat [('kemu', 'Other', 'PointOfInterest'), ('no', 'PointOfInterest', 'PointOfInterest'), ('15', 'PointOfInterest', 'Other'), ('karawang', 'Other', 'Other'), ('barat', 'Other', 'Other')]\n",
      "sai bambu apus pamulang [('sai', 'Other', 'Other'), ('bambu', 'Street', 'Street'), ('apus', 'Street', 'Street'), ('pamulang', 'Other', 'Other')]\n",
      "satriamekar del 1 21 17510 tambun utara [('satriamekar', 'Other', 'Street'), ('del', 'Street', 'Street'), ('1', 'Other', 'Other'), ('21', 'Other', 'Other'), ('17510', 'Other', 'Other'), ('tambun', 'Other', 'Other'), ('utara', 'Other', 'Other')]\n",
      "candi pramb raya 364 6 kalipancur [('candi', 'Street', 'Other'), ('pramb', 'Street', 'Other'), ('raya', 'Street', 'Street'), ('364', 'Other', 'Other'), ('6', 'Other', 'Other'), ('kalipancur', 'Other', 'Other')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pel , banguntapan banguntapan [('pel', 'PointOfInterest', 'PointOfInterest'), (',', 'PointOfInterest', 'PointOfInterest'), ('banguntapan', 'PointOfInterest', 'Other'), ('banguntapan', 'Other', 'Street')]\n",
      "ahmad yani 27 sungai lakam karimun [('ahmad', 'Other', 'Street'), ('yani', 'Street', 'Other'), ('27', 'Street', 'Other'), ('sungai', 'Other', 'Other'), ('lakam', 'Other', 'Other'), ('karimun', 'Other', 'Other')]\n",
      "kema 2 petukangan selatan pesanggrahan [('kema', 'PointOfInterest', 'Other'), ('2', 'PointOfInterest', 'Other'), ('petukangan', 'PointOfInterest', 'Other'), ('selatan', 'PointOfInterest', 'Other'), ('pesanggrahan', 'Street', 'PointOfInterest')]\n",
      "somba opu 203 toko arl megah , [('somba', 'PointOfInterest', 'Other'), ('opu', 'PointOfInterest', 'Other'), ('203', 'Other', 'Other'), ('toko', 'Other', 'Other'), ('arl', 'Other', 'Other'), ('megah', 'Other', 'Other'), (',', 'Other', 'Other')]\n",
      "mari no 1 sindanglaya cipanas [('mari', 'PointOfInterest', 'Street'), ('no', 'Street', 'Other'), ('1', 'Other', 'PointOfInterest'), ('sindanglaya', 'Street', 'PointOfInterest'), ('cipanas', 'Street', 'Other')]\n",
      "cemp i , b10 kuta baru 3 pasar kemis [('cemp', 'Other', 'Street'), ('i', 'Street', 'Street'), (',', 'Street', 'Other'), ('b10', 'Other', 'Other'), ('kuta', 'Other', 'Other'), ('baru', 'Other', 'Other'), ('3', 'Other', 'Other'), ('pasar', 'Other', 'Other'), ('kemis', 'Other', 'Other')]\n",
      "gamp raya , pondok gede [('gamp', 'Street', 'Street'), ('raya', 'Street', 'Street'), (',', 'Other', 'Other'), ('pondok', 'Other', 'Other'), ('gede', 'Other', 'Other')]\n",
      "terminal cileungsi pangkalan rt 05 rw 02(warung mama pojok) [('terminal', 'Other', 'PointOfInterest'), ('cileungsi', 'PointOfInterest', 'PointOfInterest'), ('pangkalan', 'Other', 'Other'), ('rt', 'Other', 'Other'), ('05', 'Other', 'Other'), ('rw', 'Other', 'Other'), ('02(warung', 'Other', 'Other'), ('mama', 'Other', 'Other'), ('pojok)', 'Other', 'Other')]\n",
      "taman kota mas blv 7 [('taman', 'Other', 'Other'), ('kota', 'Other', 'Other'), ('mas', 'Street', 'Street'), ('blv', 'Street', 'Street'), ('7', 'Street', 'Street')]\n",
      "kapuk muara layar per 3 35 penjaringan [('kapuk', 'Other', 'Other'), ('muara', 'Street', 'Other'), ('layar', 'Street', 'Street'), ('per', 'Other', 'Street'), ('3', 'Other', 'Street'), ('35', 'Other', 'Other'), ('penjaringan', 'Other', 'Other')]\n",
      "moh yamin no 26 klinik pratama dokter christi , [('moh', 'Other', 'Other'), ('yamin', 'PointOfInterest', 'Other'), ('no', 'Other', 'Other'), ('26', 'Other', 'PointOfInterest'), ('klinik', 'PointOfInterest', 'PointOfInterest'), ('pratama', 'PointOfInterest', 'Other'), ('dokter', 'Street', 'Other'), ('christi', 'Street', 'Other'), (',', 'Street', 'Other')]\n",
      "rung indu iii no 39 rungkut menanggal gununganyar [('rung', 'Other', 'Street'), ('indu', 'Street', 'Street'), ('iii', 'Street', 'Street'), ('no', 'Other', 'Other'), ('39', 'Other', 'Other'), ('rungkut', 'Other', 'Other'), ('menanggal', 'Other', 'Other'), ('gununganyar', 'Other', 'Other')]\n",
      "cend ii , 15 pondok bahar 6 karang tengah [('cend', 'Other', 'Other'), ('ii', 'PointOfInterest', 'Other'), (',', 'Other', 'Other'), ('15', 'Other', 'PointOfInterest'), ('pondok', 'PointOfInterest', 'PointOfInterest'), ('bahar', 'PointOfInterest', 'Other'), ('6', 'Other', 'Other'), ('karang', 'Other', 'Other'), ('tengah', 'Other', 'Other')]\n",
      "grudo pecel pawon emak [('grudo', 'Street', 'Other'), ('pecel', 'Other', 'Other'), ('pawon', 'Other', 'Other'), ('emak', 'Other', 'Other')]\n",
      "raya penggil , 89 penggilingan rt 7 5 [('raya', 'Other', 'Street'), ('penggil', 'Street', 'Street'), (',', 'Street', 'Other'), ('89', 'Other', 'Other'), ('penggilingan', 'Other', 'Other'), ('rt', 'Other', 'Other'), ('7', 'Other', 'Other'), ('5', 'Other', 'Other')]\n",
      "toko ori , raya ploso 1 ploso [('toko', 'Other', 'Street'), ('ori', 'Street', 'Other'), (',', 'Other', 'Other'), ('raya', 'Other', 'Other'), ('ploso', 'Other', 'PointOfInterest'), ('1', 'Other', 'PointOfInterest'), ('ploso', 'Other', 'PointOfInterest')]\n",
      "gandaw , no 105 [('gandaw', 'Street', 'PointOfInterest'), (',', 'Other', 'PointOfInterest'), ('no', 'Other', 'PointOfInterest'), ('105', 'Other', 'PointOfInterest')]\n",
      "toko armira jaya , beri , kramat [('toko', 'PointOfInterest', 'Other'), ('armira', 'Other', 'Other'), ('jaya', 'Other', 'Other'), (',', 'Other', 'Other'), ('beri', 'Other', 'Other'), (',', 'Other', 'Other'), ('kramat', 'Other', 'Other')]\n",
      "candi lon , 5 lontar rw 7 sambikerep [('candi', 'Other', 'Street'), ('lon', 'Street', 'Street'), (',', 'Street', 'Street'), ('5', 'Other', 'Other'), ('lontar', 'Other', 'Other'), ('rw', 'Other', 'Other'), ('7', 'Other', 'PointOfInterest'), ('sambikerep', 'Other', 'Other')]\n",
      "toko sembako tutik , puger [('toko', 'Other', 'PointOfInterest'), ('sembako', 'Other', 'PointOfInterest'), ('tutik', 'Other', 'Other'), (',', 'Other', 'Other'), ('puger', 'Other', 'Other')]\n",
      "pela biru 2 27 pegangsaan dua rt 14 26 kelapa gading [('pela', 'Street', 'Street'), ('biru', 'Street', 'Street'), ('2', 'Street', 'Street'), ('27', 'Other', 'Other'), ('pegangsaan', 'Other', 'Other'), ('dua', 'Other', 'Other'), ('rt', 'Other', 'Other'), ('14', 'Other', 'Other'), ('26', 'Other', 'Other'), ('kelapa', 'Other', 'Other'), ('gading', 'Other', 'Other')]\n",
      "kuningan delta mas iii , 146 4 50176 semarang utara [('kuningan', 'Other', 'Other'), ('delta', 'Street', 'Street'), ('mas', 'Street', 'Street'), ('iii', 'Street', 'Street'), (',', 'Other', 'Other'), ('146', 'Other', 'Other'), ('4', 'Other', 'Other'), ('50176', 'Other', 'Other'), ('semarang', 'Other', 'Other'), ('utara', 'Other', 'Other')]\n",
      "nugraha , 36374 sungai gelam [('nugraha', 'PointOfInterest', 'PointOfInterest'), (',', 'PointOfInterest', 'PointOfInterest'), ('36374', 'PointOfInterest', 'PointOfInterest'), ('sungai', 'Other', 'Other'), ('gelam', 'Other', 'Other')]\n",
      "bukit tinggi haji allu gantorang gantarang (gangking) [('bukit', 'Street', 'Other'), ('tinggi', 'PointOfInterest', 'Other'), ('haji', 'PointOfInterest', 'Other'), ('allu', 'PointOfInterest', 'Other'), ('gantorang', 'Other', 'Other'), ('gantarang', 'Other', 'Other'), ('(gangking)', 'Other', 'Other')]\n",
      "per kramat pela 4 kebayoran baru [('per', 'Street', 'Street'), ('kramat', 'Street', 'Other'), ('pela', 'Other', 'Other'), ('4', 'Other', 'Other'), ('kebayoran', 'Other', 'Other'), ('baru', 'Other', 'Other')]\n",
      "pab motto curah pusat , wana herang , 62 [('pab', 'PointOfInterest', 'Other'), ('motto', 'PointOfInterest', 'Other'), ('curah', 'PointOfInterest', 'Other'), ('pusat', 'PointOfInterest', 'Other'), (',', 'Other', 'Other'), ('wana', 'Other', 'Other'), ('herang', 'Other', 'Other'), (',', 'Other', 'Other'), ('62', 'Other', 'Other')]\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(tqdm(data_loader)):\n",
    "    raw, batch = batch\n",
    "    padded_input, padded_target = bpemb_data_padding_with_target(batch)\n",
    "    model.zero_grad()\n",
    "    \n",
    "    predictions = model(*padded_input, padded_target)\n",
    "    predictions = predictions.permute(1, 2, 0)\n",
    "    loss_fn = nn.NLLLoss()\n",
    "    loss = loss_fn(predictions, padded_target)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    counter += 1\n",
    "    \n",
    "    writer.add_scalar(\"Loss/train\", loss, counter)\n",
    "    \n",
    "    if counter % 100 == 0:\n",
    "        TEST_IDX = 0\n",
    "        sample_raw = raw[TEST_IDX].split()\n",
    "        sample_pred = predictions[TEST_IDX].transpose(0,1).argmax(dim=1).detach().cpu().numpy()\n",
    "        sample_pred_string = [tags_converter(x) for x in sample_pred]\n",
    "        sample_target = padded_target[TEST_IDX].detach().cpu().numpy()\n",
    "        sample_target_string = [tags_converter(x) for x in sample_target]\n",
    "        compact = list(zip(sample_raw, sample_pred_string, sample_target_string))\n",
    "        print(raw[TEST_IDX], compact)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
